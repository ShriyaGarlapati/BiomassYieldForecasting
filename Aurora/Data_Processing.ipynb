{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Date Sown</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Date of Cut</th>\n",
       "      <th>Julian Day</th>\n",
       "      <th>Plant Lodge</th>\n",
       "      <th>Plant Height</th>\n",
       "      <th>Yield % or Vernal</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Unnamed: 54</th>\n",
       "      <th>Unnamed: 55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seedway 9558</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HYTEST 410</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paragon BR</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4A421</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WL 319HQ</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State    City Date Sown  Brand       Variety Date of Cut  Julian Day  \\\n",
       "0    NY  Ithaca   5/10/02    NaN  Seedway 9558     6/15/05         NaN   \n",
       "1    NY  Ithaca   5/10/02    NaN    HYTEST 410     6/15/05         NaN   \n",
       "2    NY  Ithaca   5/10/02    NaN    Paragon BR     6/15/05         NaN   \n",
       "3    NY  Ithaca   5/10/02    NaN         4A421     6/15/05         NaN   \n",
       "4    NY  Ithaca   5/10/02    NaN      WL 319HQ     6/15/05         NaN   \n",
       "\n",
       "   Plant Lodge  Plant Height  Yield % or Vernal  ...  Unnamed: 46  \\\n",
       "0          NaN           NaN                NaN  ...          NaN   \n",
       "1          NaN           NaN                NaN  ...          NaN   \n",
       "2          NaN           NaN                NaN  ...          NaN   \n",
       "3          NaN           NaN                NaN  ...          NaN   \n",
       "4          NaN           NaN                NaN  ...          NaN   \n",
       "\n",
       "   Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50  Unnamed: 51  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55  \n",
       "0          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# read in time point 1 for training\n",
    "# train on it - model 1\n",
    "# test on tp 2\n",
    "# read tp 2\n",
    "# add it to xgb - model 2\n",
    "# test on tp 3\n",
    "# read tp 3\n",
    "# add it to xgb - model 3\n",
    "# test on tp 4\n",
    "# test model 1\n",
    "data = pd.read_csv('NY_trials_2002-2022_conv_agg_updated.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ithaca' 'Cobleskill' 'Perry' 'Chazy' 'Warsaw' 'LeRoy' 'Cooperstown'\n",
      " 'Geneva' 'Aurora']\n"
     ]
    }
   ],
   "source": [
    "print(data['City'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class(df):\n",
    "    # Create a DataFrame\n",
    "    print(\"Length of Dataset before class column: \", len(df))\n",
    "    # Calculate the mean and standard deviation for the Yield column\n",
    "    mean_yield = df['Yield (tons/acre)'].mean()\n",
    "    std_yield = df['Yield (tons/acre)'].std()\n",
    "\n",
    "    # Define the thresholds based on standard deviations\n",
    "    lower_threshold = mean_yield - std_yield  # Yield less than -1 stdv below mean\n",
    "    upper_threshold = mean_yield + std_yield  # Yield more than +1 stdv above mean\n",
    "\n",
    "    # Classify yields based on the thresholds\n",
    "    def classify_yield(yield_value):\n",
    "        if yield_value < lower_threshold:\n",
    "            return 0  # Low Yield (Class 1)\n",
    "        elif lower_threshold <= yield_value <= upper_threshold:\n",
    "            return 1  # Medium Yield (Class 2)\n",
    "        else:\n",
    "            return 2  # High Yield (Class 3)\n",
    "\n",
    "    # Apply the classification function to the Yield column\n",
    "    df['class'] = df['Yield (tons/acre)'].apply(classify_yield)\n",
    "\n",
    "    # Display the result\n",
    "    #print(df)\n",
    "    print(\"Length of Dataset after: \", len(df))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \n",
    "    columns_to_keep=['Yield_Diff', 'Total Solar Radiation (W/m^2)', 'Total precipitation (mm)',\n",
    "       'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'class', 'Date of Cut']\n",
    "\n",
    "    df=df[columns_to_keep]\n",
    "    #print(df.head())\n",
    "    # Rename the column\n",
    "    df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
    "    df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
    "    #df = df.rename(columns={'Yield_Diff':'yield'})\n",
    "    #data = data.rename(columns={'Total Radiation (W/m^2)':'radiation'})\n",
    "    #data = data.rename(columns={'Total Rainfall (mm)':'rain'})\n",
    "    df = df.rename(columns={'Yield_Diff': 'yield'})\n",
    "    df = df.rename(columns={'Avg Min Temp (C)':'avg_min_temp'})\n",
    "    df = df.rename(columns={'Avg Max Temp (C)':'avg_max_temp'})\n",
    "    df = df.rename(columns={'Date of Cut':'Year'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    columns_to_keep=['Yield (tons/acre)', 'Total Solar Radiation (W/m^2)', 'Total precipitation (mm)',\n",
    "       'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'Date of Cut']\n",
    "\n",
    "    df=df[columns_to_keep]\n",
    "    #print(df.head())\n",
    "    # Rename the column\n",
    "    df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
    "    df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
    "    #df3 = df3.rename(columns={'Yield_Diff':'yield'})\n",
    "    #data = data.rename(columns={'Total Radiation (W/m^2)':'radiation'})\n",
    "    #data = data.rename(columns={'Total Rainfall (mm)':'rain'})\n",
    "    df = df.rename(columns={'Avg Min Temp (C)':'avg_min_temp'})\n",
    "    df = df.rename(columns={'Avg Max Temp (C)':'avg_max_temp'})\n",
    "    df = df.rename(columns={'Date of Cut':'Year'})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_for_City(city,df):\n",
    "    city_datasets = {city: city_df for city, city_df in df.groupby(\"City\")}\n",
    "    data=city_datasets.get(city)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Year' and take the mean for numeric columns\n",
    "def create_consise_dataset(df):\n",
    "    df_grouped = df.groupby(\"Year\", as_index=False).mean(numeric_only=True)\n",
    "\n",
    "    # Add back the 'City' column (if it's the same for all rows in a group)\n",
    "    df_grouped[\"City\"] = df.groupby(\"Year\")[\"City\"].first().values\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_to_year(df):\n",
    "    df['Year'] = pd.to_datetime(df['Year'], errors='coerce')\n",
    "    # Now extract the year\n",
    "    df['Year'] = df['Year'].dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "def apply_smote(df, target_column):\n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Count occurrences of each class\n",
    "    class_counts = y.value_counts()\n",
    "\n",
    "    # Filter out classes with only 1 sample (since SMOTE cannot handle them)\n",
    "    valid_classes = class_counts[class_counts > 1].index\n",
    "    df_filtered = df[df[target_column].isin(valid_classes)]\n",
    "\n",
    "    # Update X, y after filtering\n",
    "    X_filtered = df_filtered.drop(columns=[target_column])\n",
    "    y_filtered = df_filtered[target_column]\n",
    "\n",
    "    # Set dynamic k_neighbors (ensure it's valid)\n",
    "    min_class_size = class_counts.min()\n",
    "    k_neighbors = max(1, min(min_class_size - 1, 5))  # Ensures valid k_neighbors\n",
    "\n",
    "    # Apply SMOTE only if at least 2 classes remain\n",
    "    if len(y_filtered.unique()) > 1:\n",
    "        smote = SMOTE(sampling_strategy=\"auto\", random_state=42, k_neighbors=k_neighbors)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_filtered, y_filtered)\n",
    "\n",
    "        # Convert back to DataFrame\n",
    "        df_resampled = pd.DataFrame(X_resampled, columns=X_filtered.columns)\n",
    "        df_resampled[target_column] = y_resampled\n",
    "    else:\n",
    "        print(\"SMOTE not applied: Not enough class diversity after filtering.\")\n",
    "        return df_filtered\n",
    "\n",
    "    return df_resampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def balance_data_by_year_upsample(df):\n",
    "    \"\"\"Ensures equal number of data points for each year by upsampling to the maximum year count.\"\"\"\n",
    "    \n",
    "    # Check if 'Year' exists\n",
    "    if \"Year\" not in df.columns:\n",
    "        raise KeyError(\"The dataset does not contain a 'Year' column.\")\n",
    "    \n",
    "    # Group by 'Year' and get the count of records per year\n",
    "    year_counts = df['Year'].value_counts()\n",
    "    #print(year_counts)\n",
    "    # Get the maximum number of records across all years\n",
    "    max_count = year_counts.max()\n",
    "    #print(max_count)\n",
    "    # Initialize an empty list to store balanced data\n",
    "    balanced_data = []\n",
    "\n",
    "    # Iterate over each year and sample the same number of records\n",
    "    for year in year_counts.index:\n",
    "        year_data = df[df['Year'] == year]\n",
    "        \n",
    "        # If there are fewer data points than the maximum, upsample to the max_count\n",
    "        if len(year_data) < max_count:\n",
    "            year_data = year_data.sample(n=max_count, replace=True, random_state=42)\n",
    "            #print(\"Upsampling\")\n",
    "        # Append the sampled data to the list\n",
    "        balanced_data.append(year_data)\n",
    "    #print(balanced_data)\n",
    "    # Concatenate all the sampled data into a single DataFrame\n",
    "    balanced_df = pd.concat(balanced_data, axis=0)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Total Solar Radiation (W/m^2)', 'Total precipitation (mm)', 'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'Date of Cut'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mdata_cleaning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#print(data.head())\u001b[39;00m\n\u001b[1;32m      3\u001b[0m data\u001b[38;5;241m=\u001b[39msplit_dataset_for_City(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAurora\u001b[39m\u001b[38;5;124m'\u001b[39m,data)\n",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m, in \u001b[0;36mdata_cleaning\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdata_cleaning\u001b[39m(df):\n\u001b[1;32m      2\u001b[0m     columns_to_keep\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYield (tons/acre)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Solar Radiation (W/m^2)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal precipitation (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Min Temp (C)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Max Temp (C)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate of Cut\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m     df\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns_to_keep\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#print(df.head())\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Rename the column\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Solar Radiation (W/m^2)\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradiation\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Total Solar Radiation (W/m^2)', 'Total precipitation (mm)', 'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'Date of Cut'] not in index\""
     ]
    }
   ],
   "source": [
    "data=data_cleaning(data)\n",
    "#print(data.head())\n",
    "data=split_dataset_for_City('Aurora',data)\n",
    "data=create_consise_dataset(data)\n",
    "# Sort by 'Year' to maintain the chronological order\n",
    "data=convert_date_to_year(data)\n",
    "data = data.sort_values(by=\"Year\")\n",
    "#print(\"Before upsampling\")\n",
    "#print(\"Before undersampling\")\n",
    "print(\"Before SMOTE\")\n",
    "data.drop(columns=['City'], inplace=True)\n",
    "print(data.head())\n",
    "\n",
    "print(data[\"Year\"].value_counts())  # Check class balance after SMOTE\n",
    "\n",
    "#data=balance_data_by_year_upsample(data)\n",
    "#data=undersampling(data)\n",
    "#print(\"After Undersampling\")\n",
    "data=apply_smote(data,'Year')\n",
    "\n",
    "\n",
    "\n",
    "print(\"After SMOTE\")\n",
    "print(data[\"Year\"].value_counts())  # Check class balance after SMOTE\n",
    "data=create_class(data)\n",
    "data = data.sort_values(by=\"Year\")\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(len(data))\n",
    "print(data.head())\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020 2021 2022]\n"
     ]
    }
   ],
   "source": [
    "print(data['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.680588  123759.62  1128.72        4.5745       14.7620      2\n",
      "1  0.544118  137685.25  1218.40        5.4868       15.8617      1\n",
      "2  0.602353  156512.67  1354.89        6.6452       17.1282      1\n",
      "3  2.244118  221898.34  1826.29        4.4815       14.7548      2\n",
      "4  1.497647  234944.58  1996.48        5.0604       15.3513      1\n"
     ]
    }
   ],
   "source": [
    "data_Df=data[data['Year'] != 2022]\n",
    "data_Df = data_Df.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "data_Df=data_Df.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(data_Df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "6  1.060588  327504.91  3008.62        4.5918       14.8351      1\n",
      "7  0.447647  344365.89  3094.04        4.9374       15.2594      1\n",
      "8  0.561176  365104.62  3362.26        5.5104       15.8666      1\n"
     ]
    }
   ],
   "source": [
    "target_Df=data[data['Year'] == 2022]\n",
    "target_Df = target_Df.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "target_Df=target_Df.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(target_Df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(target_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.680588  123759.62  1128.72        4.5745       14.7620      2\n",
      "1  0.544118  137685.25  1218.40        5.4868       15.8617      1\n",
      "2  0.602353  156512.67  1354.89        6.6452       17.1282      1\n",
      "3  2.244118  221898.34  1826.29        4.4815       14.7548      2\n",
      "4  1.497647  234944.58  1996.48        5.0604       15.3513      1\n"
     ]
    }
   ],
   "source": [
    "all_yearsDf=data\n",
    "all_yearsDf = all_yearsDf.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "all_yearsDf=all_yearsDf.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(all_yearsDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(all_yearsDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df=target_Df.dropna()\n",
    "all_yearsDf=all_yearsDf.dropna()\n",
    "data_Df=data_Df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df.reset_index(drop=True, inplace=True)\n",
    "all_yearsDf.reset_index(drop=True, inplace=True)\n",
    "data_Df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.060588  327504.91  3008.62        4.5918       14.8351      1\n",
      "1  0.447647  344365.89  3094.04        4.9374       15.2594      1\n",
      "2  0.561176  365104.62  3362.26        5.5104       15.8666      1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(target_Df.head())\n",
    "print(len(target_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.680588  123759.62  1128.72        4.5745       14.7620      2\n",
      "1  0.544118  137685.25  1218.40        5.4868       15.8617      1\n",
      "2  0.602353  156512.67  1354.89        6.6452       17.1282      1\n",
      "3  2.244118  221898.34  1826.29        4.4815       14.7548      2\n",
      "4  1.497647  234944.58  1996.48        5.0604       15.3513      1\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(all_yearsDf.head())\n",
    "print(len(all_yearsDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Df.to_csv(\"data_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(data_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Class 0 has no valid data after removing NaNs.\n",
      "Number of records to generate:  13333\n"
     ]
    }
   ],
   "source": [
    "# from sdv.tabular import TVAE\n",
    "\n",
    "# model = TVAE()\n",
    "# model.fit(data)\n",
    "import numpy as np\n",
    "samples_out = 20000 # total number of samples/records to generate/synthesize\n",
    "no_stds = 1 # number of standard deviations within which synthesized values must fall\n",
    "number_of_classes = (data1['class'].unique()).size # number of unique classes in input data\n",
    "\n",
    "data_len = len(data1.index)\n",
    "F = [] # a list of the feature vectors dataframes, one per class\n",
    "for class_no in range(number_of_classes):\n",
    "    df = pd.DataFrame(data1[data1['class'] == class_no])\n",
    "    #print(\"In F: \")\n",
    "    #print(check_nan_in_dataframe(df))\n",
    "    F.append(df)\n",
    "\n",
    "\n",
    "def synthesize_tabular_data(F, samples_out, no_stds, no_classes, no_records):\n",
    "    new_F = []\n",
    "    for index, entry in enumerate(F):\n",
    "        # Clean NaN values before processing\n",
    "        entry = entry.dropna(subset=['yield', 'radiation', 'rain', 'avg_max_temp', 'avg_min_temp'])\n",
    "\n",
    "        # Check if there's data left after dropping NaN values\n",
    "        if len(entry) == 0:\n",
    "            print(f\"Warning: Class {index} has no valid data after removing NaNs.\")\n",
    "            continue\n",
    "        yield_ = entry['yield']\n",
    "        mean_yield = yield_.mean()\n",
    "        std_yield = yield_.std()\n",
    "        total_rad = entry['radiation']\n",
    "        mean_rad = total_rad.mean()\n",
    "        std_rad = total_rad.std()\n",
    "        total_rain = entry['rain']\n",
    "        mean_rain = total_rain.mean()\n",
    "        std_rain = total_rain.std()\n",
    "        avg_max_temp = entry['avg_max_temp']\n",
    "        mean_max_temp = avg_max_temp.mean()\n",
    "        std_max_temp = avg_max_temp.std()\n",
    "        avg_min_temp = entry['avg_min_temp']\n",
    "        mean_min_temp = avg_min_temp.mean()\n",
    "        std_min_temp = avg_min_temp.std()\n",
    "        \n",
    "        #print(str(mean_yield) + \" \" + str(std_yield) + \" \" + str(mean_rad) + \" \" + str(std_rad) + \" \" + str(mean_rain) + \" \" + str(std_rain) + \" \" + str(mean_max_temp) + \" \" + str(std_max_temp) + \" \" + str(mean_min_temp) + \" \" + str(std_min_temp))\n",
    "        # Check for NaNs in calculated values\n",
    "        if np.isnan(mean_yield) or np.isnan(std_yield):\n",
    "            print(f\"Warning: NaN found in 'yield' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_rad) or np.isnan(std_rad):\n",
    "            print(f\"Warning: NaN found in 'radiation' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_rain) or np.isnan(std_rain):\n",
    "            print(f\"Warning: NaN found in 'rain' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_max_temp) or np.isnan(std_max_temp):\n",
    "            print(f\"Warning: NaN found in 'avg_max_temp' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_min_temp) or np.isnan(std_min_temp):\n",
    "            print(f\"Warning: NaN found in 'avg_min_temp' statistics for class {index}.\")\n",
    "            continue\n",
    "        \n",
    "        new_yields = []\n",
    "        new_rads = []\n",
    "        new_rains = []\n",
    "        new_max_temps = []\n",
    "        new_min_temps = []\n",
    "        \n",
    "        # calculate potcii: percentage of this class in input\n",
    "        potcii = (len(entry)/no_records)\n",
    "        no_records_to_generate = round(potcii * samples_out)\n",
    "        print(\"Number of records to generate: \", no_records_to_generate)\n",
    "        for i in range(no_records_to_generate):\n",
    "            new_yield = random.uniform(mean_yield - std_yield*no_stds, mean_yield + std_yield*no_stds)\n",
    "            new_yields.append(new_yield)\n",
    "            #print(\"New Yields:\")\n",
    "            #print(new_yields)\n",
    "            \n",
    "            new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "            new_rads.append(new_rad)\n",
    "            #print(\"Radiation:\")\n",
    "            #print(new_rads)\n",
    "            \n",
    "            new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "            new_rains.append(new_rain)\n",
    "            #print(\"Precipitation:\")\n",
    "            #print(new_rains)\n",
    "        \n",
    "            new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "            new_max_temps.append(new_max_temp)\n",
    "            #print(\"Max Temp:\")\n",
    "            #print(new_max_temps)\n",
    "            \n",
    "            new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "            new_min_temps.append(new_min_temp)\n",
    "            #print(\"Min Temperature\")\n",
    "            #print(new_min_temps)\n",
    "            \n",
    "        # Create a DataFrame for the new synthesized data\n",
    "        new_data = pd.DataFrame({\n",
    "            'yield': new_yields,\n",
    "            'radiation': new_rads,\n",
    "            'rain': new_rains,\n",
    "            'avg_max_temp': new_max_temps,\n",
    "            'avg_min_temp': new_min_temps,\n",
    "            'class': [index] * len(new_yields)  # Adding the class label\n",
    "        })\n",
    "        \n",
    "        # Concatenate the original data with the new synthesized data\n",
    "        concat_data = pd.concat([entry, new_data], ignore_index=True)\n",
    "        \n",
    "        # Append the concatenated DataFrame to the list\n",
    "        new_F.append(concat_data)\n",
    "    \n",
    "    # Finally, concatenate all class DataFrames into a single DataFrame\n",
    "    final_data = pd.concat(new_F, ignore_index=True)\n",
    "    \n",
    "    return final_data\n",
    "    #return pd.concat(new_F)\n",
    "\n",
    "new_data = synthesize_tabular_data(F, samples_out, no_stds, number_of_classes, data_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13337\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(\"data_no_2022_synthesized_nonstationary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df.reset_index(drop=True, inplace=True)\n",
    "all_yearsDf.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yearsDf.to_csv(\"all_years.csv\", index=False)\n",
    "target_Df.to_csv(\"target_yearDf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
