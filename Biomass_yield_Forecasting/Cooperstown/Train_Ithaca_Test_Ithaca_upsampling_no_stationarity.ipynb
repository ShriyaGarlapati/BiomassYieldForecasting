{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a6d61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Date Sown</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Date of Cut</th>\n",
       "      <th>Julian Day</th>\n",
       "      <th>Plant Lodge</th>\n",
       "      <th>Plant Height</th>\n",
       "      <th>Yield % or Vernal</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Unnamed: 54</th>\n",
       "      <th>Unnamed: 55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seedway 9558</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HYTEST 410</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paragon BR</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4A421</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WL 319HQ</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State    City Date Sown  Brand       Variety Date of Cut  Julian Day  \\\n",
       "0    NY  Ithaca   5/10/02    NaN  Seedway 9558     6/15/05         NaN   \n",
       "1    NY  Ithaca   5/10/02    NaN    HYTEST 410     6/15/05         NaN   \n",
       "2    NY  Ithaca   5/10/02    NaN    Paragon BR     6/15/05         NaN   \n",
       "3    NY  Ithaca   5/10/02    NaN         4A421     6/15/05         NaN   \n",
       "4    NY  Ithaca   5/10/02    NaN      WL 319HQ     6/15/05         NaN   \n",
       "\n",
       "   Plant Lodge  Plant Height  Yield % or Vernal  ...  Unnamed: 46  \\\n",
       "0          NaN           NaN                NaN  ...          NaN   \n",
       "1          NaN           NaN                NaN  ...          NaN   \n",
       "2          NaN           NaN                NaN  ...          NaN   \n",
       "3          NaN           NaN                NaN  ...          NaN   \n",
       "4          NaN           NaN                NaN  ...          NaN   \n",
       "\n",
       "   Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50  Unnamed: 51  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55  \n",
       "0          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# read in time point 1 for training\n",
    "# train on it - model 1\n",
    "# test on tp 2\n",
    "# read tp 2\n",
    "# add it to xgb - model 2\n",
    "# test on tp 3\n",
    "# read tp 3\n",
    "# add it to xgb - model 3\n",
    "# test on tp 4\n",
    "# test model 1\n",
    "data = pd.read_csv('NY_trials_2002-2022_conv_agg_updated.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb8480c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class(df):\n",
    "    # Create a DataFrame\n",
    "    print(\"Length of Dataset before class column: \", len(df))\n",
    "    # Calculate the mean and standard deviation for the Yield column\n",
    "    mean_yield = df['Yield (tons/acre)'].mean()\n",
    "    std_yield = df['Yield (tons/acre)'].std()\n",
    "\n",
    "    # Define the thresholds based on standard deviations\n",
    "    lower_threshold = mean_yield - std_yield  # Yield less than -1 stdv below mean\n",
    "    upper_threshold = mean_yield + std_yield  # Yield more than +1 stdv above mean\n",
    "\n",
    "    # Classify yields based on the thresholds\n",
    "    def classify_yield(yield_value):\n",
    "        if yield_value < lower_threshold:\n",
    "            return 0  # Low Yield (Class 1)\n",
    "        elif lower_threshold <= yield_value <= upper_threshold:\n",
    "            return 1  # Medium Yield (Class 2)\n",
    "        else:\n",
    "            return 2  # High Yield (Class 3)\n",
    "\n",
    "    # Apply the classification function to the Yield column\n",
    "    df['class'] = df['Yield (tons/acre)'].apply(classify_yield)\n",
    "\n",
    "    # Display the result\n",
    "    #print(df)\n",
    "    print(\"Length of Dataset after: \", len(df))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12cc85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yield(df):\n",
    "    # Load your dataset (update filename accordingly)\n",
    "    print(\"Length of Dataset before transformation: \", len(df))\n",
    "    # Ensure 'Date of Cut' is in datetime format and extract the year\n",
    "    df['Date of Cut'] = pd.to_datetime(df['Date of Cut'], errors='coerce')\n",
    "    df['Year'] = df['Date of Cut'].dt.year\n",
    "\n",
    "    # Sort data by location and year (adjust columns based on your dataset structure)\n",
    "    df = df.sort_values(by=['State', 'City', 'Year'])\n",
    "\n",
    "    # Compute year-over-year differences for yield\n",
    "    df['Yield_Diff'] = df.groupby(['State', 'City'])['Yield (tons/acre)'].diff()\n",
    "\n",
    "    # Drop rows with NaN (first year will have NaN since there's no previous year)\n",
    "    #df = df.dropna()\n",
    "\n",
    "    # Save the transformed dataset\n",
    "    #df.to_csv(\"transformed_dataset.csv\", index=False)\n",
    "\n",
    "    print(\"Transformation complete! Saved as 'transformed_dataset.csv'\")\n",
    "\n",
    "\n",
    "    # Now, create the final dataset with 'yield_diff' and other columns\n",
    "    final_output = df[['State', 'City', 'Date Sown', 'Yield_Diff', 'Total Solar Radiation (W/m^2)',\n",
    "                            'Total precipitation (mm)', 'Avg Min Temp (C)', 'Avg Max Temp (C)', 'class', 'Date of Cut']]\n",
    "\n",
    "    # Display the output\n",
    "    #print(final_output)\n",
    "    print(\"Length of dataset after transformation is: \", len(final_output))\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710783a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \n",
    "    columns_to_keep=['Yield_Diff', 'Total Solar Radiation (W/m^2)', 'Total precipitation (mm)',\n",
    "       'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'class', 'Date of Cut']\n",
    "\n",
    "    df=df[columns_to_keep]\n",
    "    #print(df.head())\n",
    "    # Rename the column\n",
    "    df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
    "    df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
    "    #df = df.rename(columns={'Yield_Diff':'yield'})\n",
    "    #data = data.rename(columns={'Total Radiation (W/m^2)':'radiation'})\n",
    "    #data = data.rename(columns={'Total Rainfall (mm)':'rain'})\n",
    "    df = df.rename(columns={'Yield_Diff': 'yield'})\n",
    "    df = df.rename(columns={'Avg Min Temp (C)':'avg_min_temp'})\n",
    "    df = df.rename(columns={'Avg Max Temp (C)':'avg_max_temp'})\n",
    "    df = df.rename(columns={'Date of Cut':'Year'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1be14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67704528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    columns_to_keep=['Yield (tons/acre)', 'Total Solar Radiation (W/m^2)', 'Total precipitation (mm)',\n",
    "       'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'Date of Cut']\n",
    "\n",
    "    df=df[columns_to_keep]\n",
    "    #print(df.head())\n",
    "    # Rename the column\n",
    "    df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
    "    df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
    "    #df3 = df3.rename(columns={'Yield_Diff':'yield'})\n",
    "    #data = data.rename(columns={'Total Radiation (W/m^2)':'radiation'})\n",
    "    #data = data.rename(columns={'Total Rainfall (mm)':'rain'})\n",
    "    df = df.rename(columns={'Avg Min Temp (C)':'avg_min_temp'})\n",
    "    df = df.rename(columns={'Avg Max Temp (C)':'avg_max_temp'})\n",
    "    df = df.rename(columns={'Date of Cut':'Year'})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4a4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_for_City(city,df):\n",
    "    city_datasets = {city: city_df for city, city_df in df.groupby(\"City\")}\n",
    "    data=city_datasets.get(city)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aaf1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Year' and take the mean for numeric columns\n",
    "def create_consise_dataset(df):\n",
    "    df_grouped = df.groupby(\"Year\", as_index=False).mean(numeric_only=True)\n",
    "\n",
    "    # Add back the 'City' column (if it's the same for all rows in a group)\n",
    "    df_grouped[\"City\"] = df.groupby(\"Year\")[\"City\"].first().values\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47dc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7edb3c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_to_year(df):\n",
    "    df['Year'] = pd.to_datetime(df['Year'], errors='coerce')\n",
    "    # Now extract the year\n",
    "    df['Year'] = df['Year'].dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd4703",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4cfe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampling(df):\n",
    "    min_count = max(df[\"Year\"].value_counts().min(), 2)\n",
    "\n",
    "    # Perform undersampling (truncate each year to match min_count)\n",
    "    df_balanced = df.groupby(\"Year\").apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n",
    "    return df_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c027b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def balance_data_by_year_upsample(df):\n",
    "    \"\"\"Ensures equal number of data points for each year by upsampling to the maximum year count.\"\"\"\n",
    "    \n",
    "    # Check if 'Year' exists\n",
    "    if \"Year\" not in df.columns:\n",
    "        raise KeyError(\"The dataset does not contain a 'Year' column.\")\n",
    "    \n",
    "    # Group by 'Year' and get the count of records per year\n",
    "    year_counts = df['Year'].value_counts()\n",
    "    #print(year_counts)\n",
    "    # Get the maximum number of records across all years\n",
    "    max_count = year_counts.max()\n",
    "    #print(max_count)\n",
    "    # Initialize an empty list to store balanced data\n",
    "    balanced_data = []\n",
    "\n",
    "    # Iterate over each year and sample the same number of records\n",
    "    for year in year_counts.index:\n",
    "        year_data = df[df['Year'] == year]\n",
    "        \n",
    "        # If there are fewer data points than the maximum, upsample to the max_count\n",
    "        if len(year_data) < max_count:\n",
    "            year_data = year_data.sample(n=max_count, replace=True, random_state=42)\n",
    "            #print(\"Upsampling\")\n",
    "        # Append the sampled data to the list\n",
    "        balanced_data.append(year_data)\n",
    "    #print(balanced_data)\n",
    "    # Concatenate all the sampled data into a single DataFrame\n",
    "    balanced_df = pd.concat(balanced_data, axis=0)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cded13d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  State    City Date Sown  Brand       Variety Date of Cut  Julian Day  \\\n",
      "0    NY  Ithaca   5/10/02    NaN  Seedway 9558     6/15/05         NaN   \n",
      "1    NY  Ithaca   5/10/02    NaN    HYTEST 410     6/15/05         NaN   \n",
      "2    NY  Ithaca   5/10/02    NaN    Paragon BR     6/15/05         NaN   \n",
      "3    NY  Ithaca   5/10/02    NaN         4A421     6/15/05         NaN   \n",
      "4    NY  Ithaca   5/10/02    NaN      WL 319HQ     6/15/05         NaN   \n",
      "\n",
      "   Plant Lodge  Plant Height  Yield % or Vernal  ...  Unnamed: 46  \\\n",
      "0          NaN           NaN                NaN  ...          NaN   \n",
      "1          NaN           NaN                NaN  ...          NaN   \n",
      "2          NaN           NaN                NaN  ...          NaN   \n",
      "3          NaN           NaN                NaN  ...          NaN   \n",
      "4          NaN           NaN                NaN  ...          NaN   \n",
      "\n",
      "   Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50  Unnamed: 51  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55  \n",
      "0          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f4e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e260d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before undersampling\n",
      "     Year  Yield (tons/acre)      radiation         rain  avg_min_temp  \\\n",
      "80   2005           1.868367  192228.728163  2104.189592      3.384498   \n",
      "56   2005           2.038261  118368.720000  1340.700000      2.653400   \n",
      "52   2005           1.421923  230454.950000  2535.380000      2.449000   \n",
      "116  2005           1.770909  358003.820000  3721.110000      2.805700   \n",
      "213  2005           0.766452   48010.950000   301.990000     12.436900   \n",
      "\n",
      "     avg_max_temp    City  \n",
      "80      14.368527  Ithaca  \n",
      "56      13.607200  Ithaca  \n",
      "52      13.306700  Ithaca  \n",
      "116     13.793200  Ithaca  \n",
      "213     25.583800  Ithaca  \n",
      "After Undersampling\n",
      "Length of Dataset before class column:  48\n",
      "Length of Dataset after:  48\n",
      "48\n",
      "   Year  Yield (tons/acre)      radiation         rain  avg_min_temp  \\\n",
      "0  2005           0.768636  373381.000000  3837.770000      3.190400   \n",
      "1  2005           2.038261  118368.720000  1340.700000      2.653400   \n",
      "2  2005           1.129565  148923.230000  1512.650000      4.769600   \n",
      "3  2006           0.583333  375856.040000  4160.070000      3.700100   \n",
      "4  2006           1.796667  296396.879091  3098.416667      3.022491   \n",
      "\n",
      "   avg_max_temp    City  class  \n",
      "0     14.261800  Ithaca      0  \n",
      "1     13.607200  Ithaca      1  \n",
      "2     16.050000  Ithaca      1  \n",
      "3     14.655400  Ithaca      0  \n",
      "4     14.052218  Ithaca      1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/1748844638.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/1748844638.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/3914005513.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Year'] = pd.to_datetime(df['Year'], errors='coerce')\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/4148998726.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df.groupby(\"Year\").apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "data=data_cleaning(data)\n",
    "#print(data.head())\n",
    "data=split_dataset_for_City('Ithaca',data)\n",
    "data=create_consise_dataset(data)\n",
    "# Sort by 'Year' to maintain the chronological order\n",
    "data=convert_date_to_year(data)\n",
    "data = data.sort_values(by=\"Year\")\n",
    "#print(\"Before upsampling\")\n",
    "print(\"Before undersampling\")\n",
    "print(data.head())\n",
    "#data=balance_data_by_year_upsample(data)\n",
    "data=undersampling(data)\n",
    "print(\"After Undersampling\")\n",
    "\n",
    "data=create_class(data)\n",
    "data = data.sort_values(by=\"Year\")\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(len(data))\n",
    "print(data.head())\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a01a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Yield (tons/acre)      radiation         rain  avg_min_temp  \\\n",
      "0  2005           0.768636  373381.000000  3837.770000      3.190400   \n",
      "1  2005           2.038261  118368.720000  1340.700000      2.653400   \n",
      "2  2005           1.129565  148923.230000  1512.650000      4.769600   \n",
      "3  2006           0.583333  375856.040000  4160.070000      3.700100   \n",
      "4  2006           1.796667  296396.879091  3098.416667      3.022491   \n",
      "\n",
      "   avg_max_temp    City  class  \n",
      "0     14.261800  Ithaca      0  \n",
      "1     13.607200  Ithaca      1  \n",
      "2     16.050000  Ithaca      1  \n",
      "3     14.655400  Ithaca      0  \n",
      "4     14.052218  Ithaca      1  \n"
     ]
    }
   ],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0351d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.768636  373381.000000  3837.770000      3.190400     14.261800      0\n",
      "1  2.038261  118368.720000  1340.700000      2.653400     13.607200      1\n",
      "2  1.129565  148923.230000  1512.650000      4.769600     16.050000      1\n",
      "3  0.583333  375856.040000  4160.070000      3.700100     14.655400      0\n",
      "4  1.796667  296396.879091  3098.416667      3.022491     14.052218      1\n"
     ]
    }
   ],
   "source": [
    "all_yearsDf=data\n",
    "\n",
    "all_yearsDf=all_yearsDf.drop(columns={'Year','City'}, inplace=False)\n",
    "#print(all_yearsDf.head())\n",
    "all_yearsDf = all_yearsDf.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "print(all_yearsDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c072005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.768636  373381.000000  3837.770000      3.190400     14.261800      0\n",
      "1  2.038261  118368.720000  1340.700000      2.653400     13.607200      1\n",
      "2  1.129565  148923.230000  1512.650000      4.769600     16.050000      1\n",
      "3  0.583333  375856.040000  4160.070000      3.700100     14.655400      0\n",
      "4  1.796667  296396.879091  3098.416667      3.022491     14.052218      1\n"
     ]
    }
   ],
   "source": [
    "# Filter out rows where 'Year' is 2022\n",
    "final_yearDf = data[data['Year'] != 2022]\n",
    "final_yearDf = final_yearDf.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "# Display the filtered DataFrame\n",
    "final_yearDf=final_yearDf.drop(columns={'Year','City'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(final_yearDf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a31d3227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "45  1.466250  124268.43  1424.11        3.7791       14.9567      1\n",
      "46  1.605476  333477.75  3384.09        3.2761       14.2609      1\n",
      "47  1.082727  209414.53  2137.07        2.8145       13.8011      0\n"
     ]
    }
   ],
   "source": [
    "target_yearDf=data[data['Year'] == 2022]\n",
    "target_yearDf = target_yearDf.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "target_yearDf=target_yearDf.drop(columns={'Year','City'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(target_yearDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22fd7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_yearDf=target_yearDf.dropna()\n",
    "all_yearsDf=all_yearsDf.dropna()\n",
    "final_yearDf=final_yearDf.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c1085e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "45  1.466250  124268.43  1424.11        3.7791       14.9567      1\n",
      "46  1.605476  333477.75  3384.09        3.2761       14.2609      1\n",
      "47  1.082727  209414.53  2137.07        2.8145       13.8011      0\n",
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.768636  373381.000000  3837.770000      3.190400     14.261800      0\n",
      "1  2.038261  118368.720000  1340.700000      2.653400     13.607200      1\n",
      "2  1.129565  148923.230000  1512.650000      4.769600     16.050000      1\n",
      "3  0.583333  375856.040000  4160.070000      3.700100     14.655400      0\n",
      "4  1.796667  296396.879091  3098.416667      3.022491     14.052218      1\n",
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.768636  373381.000000  3837.770000      3.190400     14.261800      0\n",
      "1  2.038261  118368.720000  1340.700000      2.653400     13.607200      1\n",
      "2  1.129565  148923.230000  1512.650000      4.769600     16.050000      1\n",
      "3  0.583333  375856.040000  4160.070000      3.700100     14.655400      0\n",
      "4  1.796667  296396.879091  3098.416667      3.022491     14.052218      1\n"
     ]
    }
   ],
   "source": [
    "print(target_yearDf.head())\n",
    "print(all_yearsDf.head())\n",
    "print(final_yearDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83dbe584",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_yearDf.reset_index(drop=True, inplace=True)\n",
    "all_yearsDf.reset_index(drop=True, inplace=True)\n",
    "target_yearDf.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d4b153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.466250  124268.43  1424.11        3.7791       14.9567      1\n",
      "1  1.605476  333477.75  3384.09        3.2761       14.2609      1\n",
      "2  1.082727  209414.53  2137.07        2.8145       13.8011      0\n"
     ]
    }
   ],
   "source": [
    "print(target_yearDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1067f505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Date Sown</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Date of Cut</th>\n",
       "      <th>Julian Day</th>\n",
       "      <th>Plant Lodge</th>\n",
       "      <th>Plant Height</th>\n",
       "      <th>Yield % or Vernal</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Unnamed: 54</th>\n",
       "      <th>Unnamed: 55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seedway 9558</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HYTEST 410</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paragon BR</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4A421</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WL 319HQ</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State    City Date Sown  Brand       Variety Date of Cut  Julian Day  \\\n",
       "0    NY  Ithaca   5/10/02    NaN  Seedway 9558     6/15/05         NaN   \n",
       "1    NY  Ithaca   5/10/02    NaN    HYTEST 410     6/15/05         NaN   \n",
       "2    NY  Ithaca   5/10/02    NaN    Paragon BR     6/15/05         NaN   \n",
       "3    NY  Ithaca   5/10/02    NaN         4A421     6/15/05         NaN   \n",
       "4    NY  Ithaca   5/10/02    NaN      WL 319HQ     6/15/05         NaN   \n",
       "\n",
       "   Plant Lodge  Plant Height  Yield % or Vernal  ...  Unnamed: 46  \\\n",
       "0          NaN           NaN                NaN  ...          NaN   \n",
       "1          NaN           NaN                NaN  ...          NaN   \n",
       "2          NaN           NaN                NaN  ...          NaN   \n",
       "3          NaN           NaN                NaN  ...          NaN   \n",
       "4          NaN           NaN                NaN  ...          NaN   \n",
       "\n",
       "   Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50  Unnamed: 51  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55  \n",
       "0          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('NY_trials_2002-2022_conv_agg_updated.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31068768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yield2(df):\n",
    "    # Load your dataset (update filename accordingly)\n",
    "    print(\"Length of Dataset before transformation: \", len(df))\n",
    "    # Ensure 'Date of Cut' is in datetime format and extract the year\n",
    "    #df['Year'] = pd.to_datetime(df['Year'], errors='coerce')\n",
    "    #df['Year'] = df['Year'].dt.year\n",
    "\n",
    "    # Sort data by location and year (adjust columns based on your dataset structure)\n",
    "    df = df.sort_values(by=['City', 'Year'])\n",
    "\n",
    "    # Compute year-over-year differences for yield\n",
    "    df['Yield_Diff'] = df.groupby(['City'])['Yield (tons/acre)'].diff()\n",
    "\n",
    "    # Drop rows with NaN (first year will have NaN since there's no previous year)\n",
    "    #df = df.dropna()\n",
    "\n",
    "    # Save the transformed dataset\n",
    "    #df.to_csv(\"transformed_dataset.csv\", index=False)\n",
    "\n",
    "    print(\"Transformation complete! Saved as 'transformed_dataset.csv'\")\n",
    "\n",
    "\n",
    "    # Now, create the final dataset with 'yield_diff' and other columns\n",
    "    final_output = df[['City', 'Yield_Diff', 'radiation',\n",
    "                            'rain', 'avg_min_temp', 'avg_max_temp', 'class', 'Year']]\n",
    "\n",
    "    # Display the output\n",
    "    #print(final_output)\n",
    "    print(\"Length of dataset after transformation is: \", len(final_output))\n",
    "    return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53422804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Dataset before class column:  48\n",
      "Length of Dataset after:  48\n",
      "Length of Dataset before transformation:  48\n",
      "Transformation complete! Saved as 'transformed_dataset.csv'\n",
      "Length of dataset after transformation is:  48\n",
      "     City  Yield_Diff      radiation         rain  avg_min_temp  avg_max_temp  \\\n",
      "0  Ithaca         NaN  373381.000000  3837.770000      3.190400     14.261800   \n",
      "1  Ithaca    1.269625  118368.720000  1340.700000      2.653400     13.607200   \n",
      "2  Ithaca   -0.908696  148923.230000  1512.650000      4.769600     16.050000   \n",
      "3  Ithaca   -0.546232  375856.040000  4160.070000      3.700100     14.655400   \n",
      "4  Ithaca    1.213333  296396.879091  3098.416667      3.022491     14.052218   \n",
      "\n",
      "   class  Year  \n",
      "0      0  2005  \n",
      "1      1  2005  \n",
      "2      1  2005  \n",
      "3      0  2006  \n",
      "4      1  2006  \n",
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class  \\\n",
      "0       NaN  373381.000000  3837.770000      3.190400     14.261800      0   \n",
      "1  1.269625  118368.720000  1340.700000      2.653400     13.607200      1   \n",
      "2 -0.908696  148923.230000  1512.650000      4.769600     16.050000      1   \n",
      "3 -0.546232  375856.040000  4160.070000      3.700100     14.655400      0   \n",
      "4  1.213333  296396.879091  3098.416667      3.022491     14.052218      1   \n",
      "\n",
      "   Year  \n",
      "0  2005  \n",
      "1  2005  \n",
      "2  2005  \n",
      "3  2006  \n",
      "4  2006  \n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/1748844638.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/1748844638.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/3914005513.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Year'] = pd.to_datetime(df['Year'], errors='coerce')\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/4148998726.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_balanced = df.groupby(\"Year\").apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "data=data_cleaning(data)\n",
    "#print(data.head())\n",
    "data=split_dataset_for_City('Ithaca',data)\n",
    "#print(data.head())\n",
    "data=create_consise_dataset(data)\n",
    "#print(data.head())\n",
    "data=convert_date_to_year(data)\n",
    "#print(data.head())\n",
    "data = data.sort_values(by=\"Year\")\n",
    "#data=balance_data_by_year_upsample(data)\n",
    "#print(data.head())\n",
    "#data=balance_data_by_year_upsample(data)\n",
    "data=undersampling(data)\n",
    "#print(data.head())\n",
    "#print(len(data))\n",
    "data=create_class(data)\n",
    "#print(data.head())\n",
    "data=calculate_yield2(data)\n",
    "data = data.sort_values(by=\"Year\")\n",
    "print(data.head())\n",
    "data.rename(columns={'Yield_Diff': 'yield'}, inplace=True)\n",
    "data.drop('City', axis=1, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63e79262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class  \\\n",
      "0       NaN  373381.000000  3837.770000      3.190400     14.261800      0   \n",
      "1  1.269625  118368.720000  1340.700000      2.653400     13.607200      1   \n",
      "2 -0.908696  148923.230000  1512.650000      4.769600     16.050000      1   \n",
      "3 -0.546232  375856.040000  4160.070000      3.700100     14.655400      0   \n",
      "4  1.213333  296396.879091  3098.416667      3.022491     14.052218      1   \n",
      "\n",
      "   Year  \n",
      "0  2005  \n",
      "1  2005  \n",
      "2  2005  \n",
      "3  2006  \n",
      "4  2006  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ea6ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "       yield  radiation     rain  avg_min_temp  avg_max_temp  class  Year\n",
      "46 -0.139226  124268.43  1424.11        3.7791       14.9567      1  2022\n",
      "45 -0.336797  333477.75  3384.09        3.2761       14.2609      1  2022\n",
      "47 -0.383523  209414.53  2137.07        2.8145       13.8011      0  2022\n"
     ]
    }
   ],
   "source": [
    "# List of years you want to filter\n",
    "years_to_filter = [2022]\n",
    "\n",
    "# Filter records where the 'Year' matches any of the values in the list\n",
    "data_2022 = data[data['Year'].isin(years_to_filter)]\n",
    "\n",
    "# Display the filtered records\n",
    "print(len(data_2022))\n",
    "print(data_2022.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14710782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class  \\\n",
      "0       NaN  373381.000000  3837.770000      3.190400     14.261800      0   \n",
      "1  1.269625  118368.720000  1340.700000      2.653400     13.607200      1   \n",
      "2 -0.908696  148923.230000  1512.650000      4.769600     16.050000      1   \n",
      "3 -0.546232  375856.040000  4160.070000      3.700100     14.655400      0   \n",
      "4  1.213333  296396.879091  3098.416667      3.022491     14.052218      1   \n",
      "\n",
      "   Year  \n",
      "0  2005  \n",
      "1  2005  \n",
      "2  2005  \n",
      "3  2006  \n",
      "4  2006  \n"
     ]
    }
   ],
   "source": [
    "# List of years you want to filter\n",
    "years_to_filter = [2005, 2006, 2007, 2008, 2009, 2010, 2011, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "# Filter records where the 'Year' matches any of the values in the list\n",
    "data_no_2022 = data[data['Year'].isin(years_to_filter)]\n",
    "\n",
    "# Display the filtered records\n",
    "print(len(data_no_2022))\n",
    "print(data_no_2022.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53f63f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class  Year\n",
      "0       NaN  373381.00  3837.77        3.1904       14.2618      0  2005\n",
      "1  1.269625  118368.72  1340.70        2.6534       13.6072      1  2005\n",
      "2 -0.908696  148923.23  1512.65        4.7696       16.0500      1  2005\n",
      "6 -0.945207  159773.14  1638.65        5.0332       16.2771      0  2007\n",
      "7  1.054885  245786.57  2382.68        3.6145       14.7802      1  2007\n"
     ]
    }
   ],
   "source": [
    "# List of years you want to filter\n",
    "years_to_filter = [2005, 2007, 2009, 2011, 2015, 2017, 2019, 2020, 2021]\n",
    "\n",
    "# Filter records where the 'Year' matches any of the values in the list\n",
    "boost_Df = data[data['Year'].isin(years_to_filter)]\n",
    "\n",
    "# Display the filtered records\n",
    "print(len(boost_Df))\n",
    "print(boost_Df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c55276d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/1064651002.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_no_2022.drop(columns=['Year'], inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/1064651002.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_2022.drop(columns=['Year'], inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_7911/1064651002.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  boost_Df.drop(columns=['Year'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data_no_2022.drop(columns=['Year'], inplace=True)\n",
    "data_2022.drop(columns=['Year'], inplace=True)\n",
    "boost_Df.drop(columns=['Year'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "944389ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022=data_2022.dropna()\n",
    "data_no_2022=data_no_2022.dropna()\n",
    "boost_Df=boost_Df.dropna()\n",
    "targetDf=data_2022\n",
    "data=data_no_2022\n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2498e4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [yield, radiation, rain, avg_min_temp, avg_max_temp, class]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Print rows with NaN values\n",
    "nan_rows = data[data.isna().any(axis=1)]\n",
    "\n",
    "print(\"Rows with NaN values:\")\n",
    "print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb91a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "1  1.269625  118368.720000  1340.700000      2.653400     13.607200      1\n",
      "2 -0.908696  148923.230000  1512.650000      4.769600     16.050000      1\n",
      "3 -0.546232  375856.040000  4160.070000      3.700100     14.655400      0\n",
      "4  1.213333  296396.879091  3098.416667      3.022491     14.052218      1\n",
      "5 -0.318602  128832.070000  1332.090000      4.637300     15.905100      1\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be589438",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc7fc3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.269625  118368.720000  1340.700000      2.653400     13.607200      1\n",
      "1 -0.908696  148923.230000  1512.650000      4.769600     16.050000      1\n",
      "2 -0.546232  375856.040000  4160.070000      3.700100     14.655400      0\n",
      "3  1.213333  296396.879091  3098.416667      3.022491     14.052218      1\n",
      "4 -0.318602  128832.070000  1332.090000      4.637300     15.905100      1\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8ed05b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records to generate:  2727\n",
      "Number of records to generate:  12727\n",
      "Number of records to generate:  4545\n"
     ]
    }
   ],
   "source": [
    "# from sdv.tabular import TVAE\n",
    "\n",
    "# model = TVAE()\n",
    "# model.fit(data)\n",
    "import numpy as np\n",
    "samples_out = 20000 # total number of samples/records to generate/synthesize\n",
    "no_stds = 1.5 # number of standard deviations within which synthesized values must fall\n",
    "number_of_classes = (data['class'].unique()).size # number of unique classes in input data\n",
    "\n",
    "data_len = len(data.index)\n",
    "F = [] # a list of the feature vectors dataframes, one per class\n",
    "for class_no in range(number_of_classes):\n",
    "    df = pd.DataFrame(data[data['class'] == class_no])\n",
    "    #print(\"In F: \")\n",
    "    #print(check_nan_in_dataframe(df))\n",
    "    F.append(df)\n",
    "\n",
    "\n",
    "def synthesize_tabular_data(F, samples_out, no_stds, no_classes, no_records):\n",
    "    new_F = []\n",
    "    for index, entry in enumerate(F):\n",
    "        # Clean NaN values before processing\n",
    "        entry = entry.dropna(subset=['yield', 'radiation', 'rain', 'avg_max_temp', 'avg_min_temp'])\n",
    "\n",
    "        # Check if there's data left after dropping NaN values\n",
    "        if len(entry) == 0:\n",
    "            print(f\"Warning: Class {index} has no valid data after removing NaNs.\")\n",
    "            continue\n",
    "        yield_ = entry['yield']\n",
    "        mean_yield = yield_.mean()\n",
    "        std_yield = yield_.std()\n",
    "        total_rad = entry['radiation']\n",
    "        mean_rad = total_rad.mean()\n",
    "        std_rad = total_rad.std()\n",
    "        total_rain = entry['rain']\n",
    "        mean_rain = total_rain.mean()\n",
    "        std_rain = total_rain.std()\n",
    "        avg_max_temp = entry['avg_max_temp']\n",
    "        mean_max_temp = avg_max_temp.mean()\n",
    "        std_max_temp = avg_max_temp.std()\n",
    "        avg_min_temp = entry['avg_min_temp']\n",
    "        mean_min_temp = avg_min_temp.mean()\n",
    "        std_min_temp = avg_min_temp.std()\n",
    "        \n",
    "        #print(str(mean_yield) + \" \" + str(std_yield) + \" \" + str(mean_rad) + \" \" + str(std_rad) + \" \" + str(mean_rain) + \" \" + str(std_rain) + \" \" + str(mean_max_temp) + \" \" + str(std_max_temp) + \" \" + str(mean_min_temp) + \" \" + str(std_min_temp))\n",
    "        # Check for NaNs in calculated values\n",
    "        if np.isnan(mean_yield) or np.isnan(std_yield):\n",
    "            print(f\"Warning: NaN found in 'yield' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_rad) or np.isnan(std_rad):\n",
    "            print(f\"Warning: NaN found in 'radiation' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_rain) or np.isnan(std_rain):\n",
    "            print(f\"Warning: NaN found in 'rain' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_max_temp) or np.isnan(std_max_temp):\n",
    "            print(f\"Warning: NaN found in 'avg_max_temp' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_min_temp) or np.isnan(std_min_temp):\n",
    "            print(f\"Warning: NaN found in 'avg_min_temp' statistics for class {index}.\")\n",
    "            continue\n",
    "        \n",
    "        new_yields = []\n",
    "        new_rads = []\n",
    "        new_rains = []\n",
    "        new_max_temps = []\n",
    "        new_min_temps = []\n",
    "        \n",
    "        # calculate potcii: percentage of this class in input\n",
    "        potcii = (len(entry)/no_records)\n",
    "        no_records_to_generate = round(potcii * samples_out)\n",
    "        print(\"Number of records to generate: \", no_records_to_generate)\n",
    "        for i in range(no_records_to_generate):\n",
    "            new_yield = random.uniform(mean_yield - std_yield*no_stds, mean_yield + std_yield*no_stds)\n",
    "            new_yields.append(new_yield)\n",
    "            #print(\"New Yields:\")\n",
    "            #print(new_yields)\n",
    "            \n",
    "            new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "            new_rads.append(new_rad)\n",
    "            #print(\"Radiation:\")\n",
    "            #print(new_rads)\n",
    "            \n",
    "            new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "            new_rains.append(new_rain)\n",
    "            #print(\"Precipitation:\")\n",
    "            #print(new_rains)\n",
    "        \n",
    "            new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "            new_max_temps.append(new_max_temp)\n",
    "            #print(\"Max Temp:\")\n",
    "            #print(new_max_temps)\n",
    "            \n",
    "            new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "            new_min_temps.append(new_min_temp)\n",
    "            #print(\"Min Temperature\")\n",
    "            #print(new_min_temps)\n",
    "            \n",
    "        # Create a DataFrame for the new synthesized data\n",
    "        new_data = pd.DataFrame({\n",
    "            'yield': new_yields,\n",
    "            'radiation': new_rads,\n",
    "            'rain': new_rains,\n",
    "            'avg_max_temp': new_max_temps,\n",
    "            'avg_min_temp': new_min_temps,\n",
    "            'class': [index] * len(new_yields)  # Adding the class label\n",
    "        })\n",
    "        \n",
    "        # Concatenate the original data with the new synthesized data\n",
    "        concat_data = pd.concat([entry, new_data], ignore_index=True)\n",
    "        \n",
    "        # Append the concatenated DataFrame to the list\n",
    "        new_F.append(concat_data)\n",
    "    \n",
    "    # Finally, concatenate all class DataFrames into a single DataFrame\n",
    "    final_data = pd.concat(new_F, ignore_index=True)\n",
    "    \n",
    "    return final_data\n",
    "    #return pd.concat(new_F)\n",
    "\n",
    "new_data = synthesize_tabular_data(F, samples_out, no_stds, number_of_classes, data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "55073c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values:\n",
      "Empty DataFrame\n",
      "Columns: [yield, radiation, rain, avg_min_temp, avg_max_temp, class]\n",
      "Index: []\n",
      "20043\n"
     ]
    }
   ],
   "source": [
    "# Print rows with NaN values\n",
    "nan_rows = new_data[new_data.isna().any(axis=1)]\n",
    "\n",
    "print(\"Rows with NaN values:\")\n",
    "print(nan_rows)\n",
    "new_data=new_data.dropna()\n",
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d95ff074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yield</th>\n",
       "      <th>radiation</th>\n",
       "      <th>rain</th>\n",
       "      <th>avg_min_temp</th>\n",
       "      <th>avg_max_temp</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.139226</td>\n",
       "      <td>124268.43</td>\n",
       "      <td>1424.11</td>\n",
       "      <td>3.7791</td>\n",
       "      <td>14.9567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.336797</td>\n",
       "      <td>333477.75</td>\n",
       "      <td>3384.09</td>\n",
       "      <td>3.2761</td>\n",
       "      <td>14.2609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.383523</td>\n",
       "      <td>209414.53</td>\n",
       "      <td>2137.07</td>\n",
       "      <td>2.8145</td>\n",
       "      <td>13.8011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
       "46 -0.139226  124268.43  1424.11        3.7791       14.9567      1\n",
       "45 -0.336797  333477.75  3384.09        3.2761       14.2609      1\n",
       "47 -0.383523  209414.53  2137.07        2.8145       13.8011      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get aggregate data\n",
    "#targetDataLoc = '~/ctgan/data/ts_Highmore_SD_11_stat.csv'\n",
    "\n",
    "targetDf = data_2022 #pd.read_csv(targetDataLoc)\n",
    "aggDf = new_data #pd.read_csv(aggDataLoc)\n",
    "boostDataLoc = '~/ctgan/data/ts_Highmore_SD_99_04_07_08_10_stat.csv'\n",
    "boostDf = boost_Df\n",
    "targetDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17b2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b76ba20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggDf.to_csv(\"aggDf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f1df971",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## imports\n",
    "# general\n",
    "import statistics\n",
    "import datetime\n",
    "#from sklearn.externals import joblib # save and load models\n",
    "import random\n",
    "# data manipulation and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "## machine learning stuff\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import f_regression\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# train/testing\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score  \n",
    "# error calculations\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression # linear regression\n",
    "from sklearn.linear_model import BayesianRidge #bayesisan ridge regression\n",
    "from sklearn.svm import SVC  # support vector machines classification\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor # import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor # k-nearest neightbors for regression\n",
    "from sklearn.neural_network import MLPRegressor # neural network for regression\n",
    "from sklearn.neural_network import MLPClassifier # neural network for classification\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree regressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor  # random forest regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # adaboost for classification\n",
    "import xgboost as xgb\n",
    "# saving models\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "079f1aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the features that will not be used by the machine learning models\n",
    "\n",
    "xColumnsToKeep = [\"radiation\",\"rain\", \"avg_max_temp\", \"avg_min_temp\"]\n",
    "\n",
    "# the target to keep\n",
    "yColumnsToKeep = [\"yield\"]\n",
    "\n",
    "# get a dataframe containing the features and the targets\n",
    "xDf = all_yearsDf[xColumnsToKeep]   #To train with non-stationary data\n",
    "test_xDf = target_yearDf[xColumnsToKeep]\n",
    "boost_xDf = boost_Df[xColumnsToKeep]\n",
    "\n",
    "yDf = all_yearsDf[yColumnsToKeep]   #To train with non-stationary data\n",
    "test_yDf = target_yearDf[yColumnsToKeep]\n",
    "boost_yDf = boost_Df[yColumnsToKeep]\n",
    "\n",
    "# reset the index\n",
    "xDf = xDf.reset_index(drop=True)\n",
    "yDf = yDf.reset_index(drop=True)\n",
    "test_xDf = test_xDf.reset_index(drop=True)\n",
    "test_yDf = test_yDf.reset_index(drop=True)\n",
    "boost_xDf = boost_xDf.reset_index(drop=True)\n",
    "boost_yDf = boost_yDf.reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 2500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "xCols = list(xDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d48fcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide the warnings because training the neural network caues lots of warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# make the parameter grids for sklearn's gridsearchcv\n",
    "rfParamGrid = {\n",
    "        'model__n_estimators': [5, 10, 25, 50, 100], # Number of estimators\n",
    "        'model__max_depth': [5, 10, 15, 20], # Maximum depth of the tree\n",
    "        'model__criterion': [\"mae\"]\n",
    "    }\n",
    "knnParamGrid ={\n",
    "        'model__n_neighbors':[2,5,10],\n",
    "        'model__weights': ['uniform', 'distance'],\n",
    "        'model__leaf_size': [5, 10, 30, 50]    \n",
    "    }\n",
    "svrParamGrid = {\n",
    "        'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'model__C': [0.1, 1.0, 5.0, 10.0],\n",
    "        'model__gamma': [\"scale\", \"auto\"],\n",
    "        'model__degree': [2,3,4,5]\n",
    "    }\n",
    "nnParamGrid = {\n",
    "        'model__hidden_layer_sizes':[(3), (5), (10), (3,3), (5,5), (7,7)],\n",
    "        'model__solver': ['sgd', 'adam'],\n",
    "        'model__learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "        'model__learning_rate_init': [0.1, 0.01, 0.001]      \n",
    "    }\n",
    "\n",
    "linRegParamGrid = {}\n",
    "\n",
    "bayesParamGrid={\n",
    "        'model__n_iter':[100,300,500]\n",
    "    }\n",
    "\n",
    "dtParamGrid = {\n",
    "    'model__criterion': ['mae'],\n",
    "    'model__max_depth': [5,10,25,50,100]\n",
    "    }\n",
    "\n",
    "#xgbParamGrid = {}\n",
    "\n",
    "xgbParamGrid = {\n",
    "    'model__n_estimators': [50, 100, 200],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'model__max_depth': [3, 5, 7],\n",
    "    'model__subsample': [0.8, 1.0],\n",
    "    'model__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "aModelList = [#(RandomForestRegressor(), rfParamGrid, \"rfTup.pkl\")]#,\n",
    "              #(KNeighborsRegressor(), knnParamGrid, \"knnTup.pkl\"),\n",
    "              #(SVC(), svrParamGrid, \"svrTup.pkl\")]#,\n",
    "             #(MLPClassifier(), nnParamGrid, \"nnTup.pkl\")]#,\n",
    "             #(LinearRegression(), linRegParamGrid, \"linRegTup.pkl\")]#,\n",
    "             #(BayesianRidge(), bayesParamGrid, \"bayesTup.pkl\"),\n",
    "             #(DecisionTreeRegressor(), dtParamGrid, \"dtTup.pkl\")]\n",
    "             (xgb.XGBRegressor(), xgbParamGrid, \"xgbTup.pkl\")]\n",
    "\n",
    "N = 4\n",
    "workingDir = 'working_dir'\n",
    "numFeatures = 4 # 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a975d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check if any NaN exists in the entire DataFrame\n",
    "if xDf.isna().any().any():\n",
    "    print(\"There are NaN values in the dataset.\")\n",
    "# To check if any Infinity exists in the entire DataFrame\n",
    "if np.isinf(xDf).any().any():\n",
    "    print(\"There are Infinity values in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4f42b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_yearDf = final_yearDf.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "target_yearDf = target_yearDf.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "final_yearDf = final_yearDf.reset_index(drop=True)\n",
    "final_yearDf = final_yearDf.reset_index(drop=True)\n",
    "all_yearsDf = all_yearsDf.reset_index(drop=True)\n",
    "target_yearDf = target_yearDf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd7df128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.768636  373381.000000  3837.770000      3.190400     14.261800      0\n",
      "1  2.038261  118368.720000  1340.700000      2.653400     13.607200      1\n",
      "2  1.129565  148923.230000  1512.650000      4.769600     16.050000      1\n",
      "3  0.583333  375856.040000  4160.070000      3.700100     14.655400      0\n",
      "4  1.796667  296396.879091  3098.416667      3.022491     14.052218      1\n"
     ]
    }
   ],
   "source": [
    "print(all_yearsDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d1628353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.768636  373381.000000  3837.770000      3.190400     14.261800      0\n",
      "1  2.038261  118368.720000  1340.700000      2.653400     13.607200      1\n",
      "2  1.129565  148923.230000  1512.650000      4.769600     16.050000      1\n",
      "3  0.583333  375856.040000  4160.070000      3.700100     14.655400      0\n",
      "4  1.796667  296396.879091  3098.416667      3.022491     14.052218      1\n"
     ]
    }
   ],
   "source": [
    "print(final_yearDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a92e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.466250  124268.43  1424.11        3.7791       14.9567      1\n",
      "1  1.605476  333477.75  3384.09        3.2761       14.2609      1\n",
      "2  1.082727  209414.53  2137.07        2.8145       13.8011      0\n"
     ]
    }
   ],
   "source": [
    "print(target_yearDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba9d8512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "1  1.269625  118368.72  1340.70        2.6534       13.6072      1\n",
      "2 -0.908696  148923.23  1512.65        4.7696       16.0500      1\n",
      "6 -0.945207  159773.14  1638.65        5.0332       16.2771      0\n",
      "7  1.054885  245786.57  2382.68        3.6145       14.7802      1\n",
      "8  1.123226  233210.09  2291.76        3.2600       14.3162      2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(boost_Df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52261c51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saveMLResults' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msaveMLResults\u001b[49m(all_yearsDf, final_yearDf, target_yearDf, boost_xDf, boost_yDf, test_xDf, test_yDf, N, xDf, yDf, aModelList, workingDir, numFeatures, printResults\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'saveMLResults' is not defined"
     ]
    }
   ],
   "source": [
    "saveMLResults(all_yearsDf, final_yearDf, target_yearDf, boost_xDf, boost_yDf, test_xDf, test_yDf, N, xDf, yDf, aModelList, workingDir, numFeatures, printResults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b417e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestModel(N, xDf, yDf, emptyModel, paramGrid, features, metricToOptimize='mae'):\n",
    "    \"\"\"\n",
    "    inputs: N - int - the number of times the model should be trained and evaluated.\n",
    "            xDf - pandas dataframe - the rows represent the data points, the columns represent the features. These\n",
    "                                         are the inputs into the model\n",
    "            yDf - pandas dataframe - the rows represent the data points, there is only one column. This contains the\n",
    "                                         the target values for the model.\n",
    "            emptyModel - sklearn model - a valid sci-kit learn model with a 'fit' method.\n",
    "            paramGrid - dictionary - the para_grid to be used with this model in a grid search. Note that each parameter name\n",
    "                                     in the grid must start with 'model__' (two underscores).\n",
    "            features - int or float - if int, then use SelectKBest where k='features'. If float, use SelectPercentile \n",
    "                                      where 'features' is the percentage\n",
    "            testSize - float - the percentage of the data that should be used for the testing set (if method=='split')\n",
    "            metricToOptimize - string - either 'mae' or 'r2'.\n",
    "    outputs: avgMAE - the average mean absolute error of the model as it is evaluated N times.\n",
    "             avgRSq - the average R^2 value of the model as it is evaluated N times.\n",
    "             bestMAE - the mean absolute error of the best model out of the N iterations.\n",
    "             bestRSq - the R^2 of the best model out of the N iterations.\n",
    "             bestModel - the trained best model out of the N iterations.\n",
    "             \n",
    "    NOTE: This assumes the data in xDf has been standardized or normalized before being used in this function.\n",
    "    \"\"\"\n",
    "    # initialize the outputs\n",
    "    avgMAE = 0.0\n",
    "    avgRSq = 0.0\n",
    "    bestRSq = -9999999999.99\n",
    "    bestMAE = 9999999999.99\n",
    "    \n",
    "    # get the input features in the correct format\n",
    "    X = xDf.values\n",
    "    # put the target values in the correct format\n",
    "    columnName = yDf.columns[0]\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(yDf.index)):  # loop through every row of the dataframe\n",
    "        y.append(yDf.iloc[i, 0])\n",
    "\n",
    "    # convert the list to a numpy array\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    # make the cv settings\n",
    "    cv = KFold(n_splits=N, random_state=42, shuffle=True)\n",
    "\n",
    "    # for every fold\n",
    "    for train_index, test_index in cv.split(X):\n",
    "    #for train_index, test_index in zip(X[:224], X[224:]):\n",
    "        \n",
    "        # standardization\n",
    "        standardScaler = preprocessing.StandardScaler()\n",
    "\n",
    "        # feature selection\n",
    "        if type(features) == int:\n",
    "            featureSelection = SelectKBest(f_regression, k=features)\n",
    "        elif type(features) == float:\n",
    "            featuresPercentile = features/100.0\n",
    "            featureSelection = SelectPercentile(f_regression, percentile=featuresPercentile)\n",
    "        else:\n",
    "            raise ValueError(\"The input 'features' is not an integer or a float. It should be.\")\n",
    "\n",
    "        # make a pipeline\n",
    "        pipe = Pipeline(steps=[('standardization', standardScaler), \n",
    "                               ('feature selection', featureSelection), \n",
    "                               ('model', emptyModel)])\n",
    "\n",
    "        # get the train and test data\n",
    "        xTrain, xTest, yTrain, yTest = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "        # do a grid search and K-fold cross validation\n",
    "        numFolds = 5 # 5-Fold cross validation\n",
    "        \n",
    "       # make the model with optimized hyperparameters via a grid search with cross validation\n",
    "        model = GridSearchCV(\n",
    "             estimator=pipe,\n",
    "             param_grid=paramGrid,\n",
    "             cv=KFold(n_splits=numFolds, shuffle=True),\n",
    "             scoring='neg_mean_absolute_error',\n",
    "             return_train_score=False\n",
    "         )\n",
    "        \n",
    "        #model = xgb.XGBRegressor()\n",
    "\n",
    "        # fit model\n",
    "        model.fit(xTrain, yTrain)\n",
    "        #xgb_model.fit(xTrain, yTrain)\n",
    "\n",
    "        # get predictions\n",
    "        pred = model.predict(xTest)\n",
    "        trainPred = model.predict(xTrain)\n",
    "#         xgb_pred = xgb_model.predict(xTest)\n",
    "#         xgb_trainPred = xgb_model.predict(xTrain)\n",
    "\n",
    "        # find errors\n",
    "        meanAbsoluteError = mean_absolute_error(yTest, pred)\n",
    "        trainMeanAbsoluteError = mean_absolute_error(yTrain, trainPred)\n",
    "\n",
    "        # find the R^2 values\n",
    "        rSq = r2_score(yTest, pred)\n",
    "        trainRSq = r2_score(yTrain, trainPred)\n",
    "        \n",
    "        # calculate accuracy\n",
    "        #accuracy = accuracy_score(yTest, pred)\n",
    "        \n",
    "        # calculate f1 score\n",
    "        #f1 = f1_score(yTest, pred, average='macro')\n",
    "        \n",
    "        #calculate matthews correlation coefficient\n",
    "        #mcc = matthews_corrcoef(yTest, pred)\n",
    "\n",
    "        # add the errors and R Squared to average values\n",
    "        avgMAE += meanAbsoluteError\n",
    "        avgRSq += rSq\n",
    "\n",
    "        # check to see which metric should be optimized\n",
    "        if metricToOptimize == 'r2':\n",
    "            # check to see if any of these are the best values\n",
    "            if (rSq > bestRSq):\n",
    "                bestMAE = meanAbsoluteError\n",
    "                bestModel = model\n",
    "                bestRSq = rSq\n",
    "\n",
    "        elif metricToOptimize == 'mae':\n",
    "            # check to see if any of these are the best values\n",
    "            if (meanAbsoluteError < bestMAE):\n",
    "                bestMAE = meanAbsoluteError\n",
    "                bestModel = model\n",
    "                bestRSq = rSq\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"The input 'metricToOptimize' does not have a valid input. It must be 'r2' or 'mae'.\")\n",
    "\n",
    "    # divide the sums by N to get the averages\n",
    "    avgMAE /= N\n",
    "    avgRSq /= N\n",
    "    \n",
    "    ## get the features that were selected to train the best model\n",
    "    \n",
    "    # get all of the feature names and store in a numpy array\n",
    "    features = np.asarray(list(xDf))\n",
    "   \n",
    "    # get a boolean list to say which features were kept\n",
    "    #boolArray = bestModel.best_estimator_.named_steps['feature selection'].get_support()\n",
    "    \n",
    "    # get a list of which features were kept\n",
    "    #featuresUsed = np.ndarray.tolist(features[boolArray])\n",
    "    \n",
    "    ## return the results\n",
    "    return avgMAE, avgRSq, bestMAE, bestRSq, bestModel#, featuresUsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71ca6fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveMLResults(all_yearsDf, final_yearDf, target_yearDf, boost_xDf, boost_yDf, xTest, yTest, N, xDf, yDf, modelList, workingDir, numFeatures, printResults=True):\n",
    "    \"\"\"\n",
    "    inputs: N - int - the number of times the model should be trained and evaluated.\n",
    "            xDf - pandas dataframe - the rows represent the data points, the columns represent the features. These\n",
    "                                         are the inputs into the model\n",
    "            yDf - pandas dataframe - the rows represent the data points, there is only one column. This contains the\n",
    "                                         the target values for the model.\n",
    "            modelList - list of tuples - each tuple takes the form of \n",
    "                        (empty sklearn model, parameter grid for sklearn's gridsearchcv, name of file to be saved).\n",
    "                        The parameter grid should be a dictionary of possible parameter values for the empty model.\n",
    "                        Look at sklearn's documentation for more information\n",
    "           workingDir - string - the directory where the final results should be saved\n",
    "           numFeatures - int or float - if int, then use SelectKBest where k='features'. If float, use SelectPercentile \n",
    "                                      where 'features' is the percentage\n",
    "           printResults - boolean - if True, then also print the results. Otherwise, dont print the results\n",
    "    outputs: nothing is returned, but the results are saved at the given location. A tuple is saved of the form\n",
    "             (bestModel, bestFeatures, bestMAE, bestRSq, avgMAE, avgRSq). Each value means the following\n",
    "             -bestModel - the best model found by 'getBestModel'. Note that this is the trained sklearn model itself\n",
    "             -bestFeatures - the chosen features for the best model\n",
    "             -bestMAE - the mean absolute error of the best model\n",
    "             -bestRSq - the R squared value of the best model\n",
    "             -avgMAE - the average mean absolute error of the model over the N iterations\n",
    "             -avgRSq- the average R squared value of the model over the N iterations\n",
    "    \"\"\"\n",
    "    # for every entry in the list\n",
    "    for tup in modelList:\n",
    "        model = tup[0]\n",
    "        paramGrid = tup[1]\n",
    "        filename = tup[2]\n",
    "\n",
    "        # get results\n",
    "#         avgMAE, avgRSq, bestMAE, bestRSq, bestModel, bestFeatures = getBestModel(N, xDf, yDf, model, paramGrid, \n",
    "        avgMAE, avgRSq, bestMAE, bestRSq, bestModel = getBestModel(N, xDf, yDf, model, paramGrid, \n",
    "                                                                                 features=numFeatures, metricToOptimize='r2')\n",
    "\n",
    "        # convert tons to lbs to make results more readable\n",
    "        #avgMAE = (round(avgMAE*2000, 3))\n",
    "        #bestMAE = (round(bestMAE*2000, 3))\n",
    "\n",
    "        # get the save location\n",
    "        saveLoc = workingDir + \"/\" + filename\n",
    "\n",
    "        # get model name\n",
    "        stopIndex = filename.find(\".\")\n",
    "        modelName = filename[:stopIndex]\n",
    "\n",
    "        #save the new model over the old model if the new model has a better R^2 value\n",
    "#         joblib.dump((bestModel, bestFeatures, bestMAE, bestRSq, avgMAE, avgRSq), saveLoc)\n",
    "        joblib.dump((bestModel, bestMAE, bestRSq, avgMAE, avgRSq), saveLoc)\n",
    "        \n",
    "\n",
    "        # if 'printResults' is True, then print results\n",
    "        if printResults:\n",
    "            print(\"model: \", modelName)\n",
    "            print(\"Avg MAE: \", avgMAE)\n",
    "            print(\"Avg R squared: \", round(avgRSq, 3))\n",
    "            print(\"Best MAE: \", bestMAE)\n",
    "            print(\"Best R squared: \", round(bestRSq, 3))\n",
    "            #print(\"Parameters of the best model: \", bestModel.best_params_)\n",
    "            #print(\"Features selected by best model: \", bestFeatures)\n",
    "            print(\" \")\n",
    "            \n",
    "        m, r = actualTest(all_yearsDf, final_yearDf, target_yearDf, boost_xDf, boost_yDf, xTest, yTest, bestModel)\n",
    "        \n",
    "        print(\"non-local results:\")\n",
    "        print(\"MAE: \", m)\n",
    "        print(\"R: \", r)\n",
    "            \n",
    "        #count += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c38df539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualTest(all_yearsDf, final_yearDf, target_yearDf, boost_xDf, boost_yDf, xTest, yTest, model):\n",
    "    #print(\"Length of all_yearsDf----This is used for plotting graph \", len(all_yearsDf))\n",
    "    #print(\"Length of final_yearDf-----This is used for adjusting the predicted values: \", len(final_yearDf))\n",
    "    #print(\"Length of target_yearDf-------This is used for comparing predicted values to true values-----these are true values \", len(target_yearDf))\n",
    "    #print(\"boost_xDf: \",len(boost_xDf))\n",
    "    #print(\"boost_yDf: \", len(boost_yDf))\n",
    "    #print(\"Length of xTest: \", len(xTest))\n",
    "    #print(\"Length of yTest: \", len(yTest))\n",
    "    #print(\"test results on our test data: \")\n",
    "    #print(yTest)\n",
    "    \n",
    "    #model = model.fit(boost_xDf, boost_yDf, xgb_model=model.get_booster())\n",
    "    # get predictions\n",
    "    pred = model.predict(xTest)\n",
    "    #trainPred = model.predict(xTrain)\n",
    "    #print(\"Length of predictions are: \", len(pred))\n",
    "\n",
    "    adj_pred = []\n",
    "    for i in range(len(pred)):\n",
    "        adj_pred.append(final_yearDf['yield'][i] + pred[i])\n",
    "    #print('adjusted predictions: ')\n",
    "    #print(adj_pred)\n",
    "    #print(\"Predictions are: \")\n",
    "    #print(pred)\n",
    "    #print(\"Length of adjusted predictions: \", len(adj_pred))\n",
    "    adj_pred_Df = pd.DataFrame(adj_pred)\n",
    "    #print(adj_pred_Df)\n",
    "    adj_pred_Df=pd.DataFrame(pred)\n",
    "    # find errors\n",
    "    meanAbsoluteError = mean_absolute_error(target_yearDf['yield'], adj_pred_Df)\n",
    "\n",
    "#     plt.scatter(yTest, pred, label='Truth vs Prediction')\n",
    "#     p1 = max(max(pred), max(yTest['Yield (tons/acre)']))\n",
    "#     p2 = min(min(pred), min(yTest['Yield (tons/acre)']))\n",
    "#     plt.plot([p1, p2], [p1, p2], color='k', label='Perfect Predictions')\n",
    "#     plt.xlabel('True Yields')\n",
    "#     plt.ylabel('Predicted Yields')\n",
    "#     plt.legend()\n",
    "    #print(\"Plotting--------\")\n",
    "    pred_ts = []\n",
    "    len_tsDf = len(all_yearsDf)\n",
    "    #print(\"len_tsDf----Length of all_yearsDf----\", len_tsDf)\n",
    "    for i in range(len_tsDf - len(adj_pred), len_tsDf):\n",
    "        pred_ts.append(i)\n",
    "    #print(\"Length of pred_ts is: \", len(pred_ts))\n",
    "    #print(\"This is the index calculated for plotting time-series graph: \", pred_ts)    \n",
    "    pred_df = pd.DataFrame(adj_pred, index = pred_ts, columns = ['yield'])\n",
    "    #print(\"Lengths of all_yearsDf and Lengths of pred_Df are: \", len(all_yearsDf['yield']), len(pred_df))\n",
    "    #print(\"Head and shape of pred_Df\")\n",
    "    #print(pred_df.head())  # Check structure\n",
    "    #print(pred_df.shape)   # Compare with all_yearsDf\n",
    "    #print(all_yearsDf.index)\n",
    "    plot_series(pd.Series(all_yearsDf['yield']), pred_df, labels=[\"y\", \"y_pred\"])\n",
    "\n",
    "\n",
    "    #plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot actual yield using its index\n",
    "    #plt.plot(all_yearsDf.index, all_yearsDf['yield'], label=\"Actual Yield\", linestyle=\"-\", color=\"blue\")\n",
    "\n",
    "    # Plot predicted yield using its index (from pred_df)\n",
    "    #plt.plot(pred_df.index, pred_df['yield'], label=\"Predicted Yield\", linestyle=\"--\", color=\"red\")\n",
    "\n",
    "    #plt.xlabel(\"Index\")  # The x-axis will now be the index of each DataFrame\n",
    "    #plt.ylabel(\"Yield\")\n",
    "    #plt.legend()\n",
    "    #plt.title(\"Actual vs. Predicted Yield\")\n",
    "    #plt.show()\n",
    "\n",
    "    # find the R values\n",
    "    r = np.corrcoef(target_yearDf['yield'], adj_pred)[0,1]\n",
    "    \n",
    "    # find the R^2 coefficient of determination\n",
    "    # defining the variables\n",
    "#     r2x = xTest.tolist()\n",
    "#     r2y = yTest.tolist()\n",
    "\n",
    "    # adding the constant term\n",
    "    r2pred = sm.add_constant(adj_pred)\n",
    "\n",
    "    # performing the regression\n",
    "    # and fitting the model\n",
    "    yTargetYield = target_yearDf['yield']\n",
    "    result = sm.OLS(yTargetYield, r2pred).fit()\n",
    "\n",
    "    # printing the summary table\n",
    "    print(result.summary())\n",
    "    print('skt mape: ' + str(round(skt_mape(yTargetYield, adj_pred_Df) * 100, 3)) + '%')\n",
    "    print('skt smape: ' + str(round(skt_smape(yTargetYield, adj_pred_Df) * 100, 3)) + '%')\n",
    "    print('skt mae: ' + str(round(skt_mae(yTargetYield, adj_pred_Df), 3)))\n",
    "    print('skt mse: ' + str(round(skt_mse(yTargetYield, adj_pred_Df), 3)))\n",
    "    print('skt rmse: ' + str(round(math.sqrt(skt_mse(yTargetYield, adj_pred_Df)), 3)) + '\\n\\n')\n",
    "    \n",
    "    #accuracy = accuracy_score(yTest, pred)\n",
    "    \n",
    "    return(meanAbsoluteError, r)\n",
    "    \n",
    "\n",
    "#     # add the errors and R Squared to average values\n",
    "#     avgMAE += meanAbsoluteError\n",
    "#     avgRSq += rSq\n",
    "\n",
    "#     # check to see which metric should be optimized\n",
    "#     if metricToOptimize == 'r2':\n",
    "#         # check to see if any of these are the best values\n",
    "#         if (rSq > bestRSq):\n",
    "#             bestMAE = meanAbsoluteError\n",
    "#             bestModel = model\n",
    "#             bestRSq = rSq\n",
    "\n",
    "#     elif metricToOptimize == 'mae':\n",
    "#         # check to see if any of these are the best values\n",
    "#         if (meanAbsoluteError < bestMAE):\n",
    "#             bestMAE = meanAbsoluteError\n",
    "#             bestModel = model\n",
    "#             bestRSq = rSq\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(\"The input 'metricToOptimize' does not have a valid input. It must be 'r2' or 'mae'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "80a53908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import datetime\n",
    "#from sklearn.externals import joblib # save and load models\n",
    "import joblib\n",
    "import random\n",
    "# data manipulation and exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "## machine learning stuff\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.feature_selection import f_regression\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# train/testing\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sktime.utils.plotting import plot_series\n",
    "\n",
    "# error calculations\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, matthews_corrcoef\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression # linear regression\n",
    "from sklearn.linear_model import BayesianRidge #bayesisan ridge regression\n",
    "from sklearn.svm import SVR  # support vector machines regression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor # import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor # k-nearest neightbors for regression\n",
    "from sklearn.neural_network import MLPRegressor # neural network for regression\n",
    "from sklearn.tree import DecisionTreeRegressor # decision tree regressor\n",
    "from sklearn.ensemble import RandomForestRegressor  # random forest regression\n",
    "from sklearn.ensemble import AdaBoostRegressor # adaboost for regression\n",
    "import xgboost as xgb\n",
    "\n",
    "skt_mape = MeanAbsolutePercentageError(symmetric=False)\n",
    "skt_smape = MeanAbsolutePercentageError(symmetric=True)\n",
    "skt_mae = MeanAbsoluteError()\n",
    "skt_mse = MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0660bfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7f2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Upsampling\n",
    "\n",
    "\n",
    "\n",
    "model:  xgbTup\n",
    "Avg MAE:  0.5620175849683464\n",
    "Avg R squared:  0.41\n",
    "Best MAE:  0.5608421187074918\n",
    "Best R squared:  0.417\n",
    " \n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  yield   R-squared:                       0.042\n",
    "Model:                            OLS   Adj. R-squared:                 -0.022\n",
    "Method:                 Least Squares   F-statistic:                    0.6626\n",
    "Date:                Sun, 30 Mar 2025   Prob (F-statistic):              0.428\n",
    "Time:                        13:14:06   Log-Likelihood:                 1.7264\n",
    "No. Observations:                  17   AIC:                            0.5472\n",
    "Df Residuals:                      15   BIC:                             2.214\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const          1.0324      0.088     11.674      0.000       0.844       1.221\n",
    "x1            -0.0765      0.094     -0.814      0.428      -0.277       0.124\n",
    "==============================================================================\n",
    "Omnibus:                        0.199   Durbin-Watson:                   2.009\n",
    "Prob(Omnibus):                  0.905   Jarque-Bera (JB):                0.123\n",
    "Skew:                           0.154   Prob(JB):                        0.940\n",
    "Kurtosis:                       2.720   Cond. No.                         2.78\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "skt mape: 67.291%\n",
    "skt smape: 82.925%\n",
    "skt mae: 0.618\n",
    "skt mse: 0.53\n",
    "skt rmse: 0.728\n",
    "\n",
    "\n",
    "non-local results:\n",
    "MAE:  0.6178704736475723\n",
    "R:  -0.20567927314573065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4079a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "\n",
    "#k=10\n",
    "\n",
    "model:  xgbTup\n",
    "Avg MAE:  0.551655524049979\n",
    "Avg R squared:  0.434\n",
    "Best MAE:  0.5509496771298307\n",
    "Best R squared:  0.439\n",
    " \n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  yield   R-squared:                       0.702\n",
    "Model:                            OLS   Adj. R-squared:                  0.405\n",
    "Method:                 Least Squares   F-statistic:                     2.361\n",
    "Date:                Sun, 30 Mar 2025   Prob (F-statistic):              0.367\n",
    "Time:                        17:50:36   Log-Likelihood:                 2.0898\n",
    "No. Observations:                   3   AIC:                           -0.1796\n",
    "Df Residuals:                       1   BIC:                            -1.982\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const          1.1358      0.202      5.623      0.112      -1.431       3.702\n",
    "x1             0.2557      0.166      1.537      0.367      -1.859       2.370\n",
    "==============================================================================\n",
    "Omnibus:                          nan   Durbin-Watson:                   1.087\n",
    "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.368\n",
    "Skew:                           0.417   Prob(JB):                        0.832\n",
    "Kurtosis:                       1.500   Cond. No.                         3.09\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "skt mape: 50.543%\n",
    "skt smape: 70.947%\n",
    "skt mae: 0.658\n",
    "skt mse: 0.474\n",
    "skt rmse: 0.689\n",
    "\n",
    "\n",
    "non-local results:\n",
    "MAE:  0.6578999487511509\n",
    "R:  0.8381427090580348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "\n",
    "#k=5\n",
    "\n",
    "model:  xgbTup\n",
    "Avg MAE:  0.5515621629254313\n",
    "Avg R squared:  0.434\n",
    "Best MAE:  0.5488169445677961\n",
    "Best R squared:  0.439\n",
    " \n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  yield   R-squared:                       0.712\n",
    "Model:                            OLS   Adj. R-squared:                  0.424\n",
    "Method:                 Least Squares   F-statistic:                     2.471\n",
    "Date:                Sun, 30 Mar 2025   Prob (F-statistic):              0.361\n",
    "Time:                        19:41:58   Log-Likelihood:                 2.1379\n",
    "No. Observations:                   3   AIC:                           -0.2758\n",
    "Df Residuals:                       1   BIC:                            -2.079\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const          1.1412      0.195      5.847      0.108      -1.339       3.621\n",
    "x1             0.2541      0.162      1.572      0.361      -1.800       2.308\n",
    "==============================================================================\n",
    "Omnibus:                          nan   Durbin-Watson:                   1.096\n",
    "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.376\n",
    "Skew:                           0.434   Prob(JB):                        0.829\n",
    "Kurtosis:                       1.500   Cond. No.                         3.02\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "skt mape: 51.649%\n",
    "skt smape: 73.79%\n",
    "skt mae: 0.67\n",
    "skt mse: 0.495\n",
    "skt rmse: 0.704\n",
    "\n",
    "\n",
    "non-local results:\n",
    "MAE:  0.6702294998320136\n",
    "R:  0.8437254871576833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcc937",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling\n",
    "\n",
    "#Added adj_pred_Df=pd.DataFrame(pred)\n",
    "\n",
    "k=5\n",
    "\n",
    "\n",
    "model:  xgbTup\n",
    "Avg MAE:  0.5515621629254313\n",
    "Avg R squared:  0.434\n",
    "Best MAE:  0.5488169445677961\n",
    "Best R squared:  0.439\n",
    " \n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  yield   R-squared:                       0.712\n",
    "Model:                            OLS   Adj. R-squared:                  0.424\n",
    "Method:                 Least Squares   F-statistic:                     2.471\n",
    "Date:                Sun, 30 Mar 2025   Prob (F-statistic):              0.361\n",
    "Time:                        15:35:06   Log-Likelihood:                 2.1379\n",
    "No. Observations:                   3   AIC:                           -0.2758\n",
    "Df Residuals:                       1   BIC:                            -2.079\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const          1.1412      0.195      5.847      0.108      -1.339       3.621\n",
    "x1             0.2541      0.162      1.572      0.361      -1.800       2.308\n",
    "==============================================================================\n",
    "Omnibus:                          nan   Durbin-Watson:                   1.096\n",
    "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.376\n",
    "Skew:                           0.434   Prob(JB):                        0.829\n",
    "Kurtosis:                       1.500   Cond. No.                         3.02\n",
    "==============================================================================\n",
    "\n",
    "Notes:\n",
    "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
    "skt mape: 131.011%\n",
    "skt smape: 200.0%\n",
    "skt mae: 1.738\n",
    "skt mse: 3.047\n",
    "skt rmse: 1.745\n",
    "\n",
    "\n",
    "non-local results:\n",
    "MAE:  1.7382544376276445\n",
    "R:  0.8437254871576833"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling-----criterion: mae\n",
    "\n",
    "\n",
    "model:  xgbTup\n",
    "Avg MAE:  0.5524303574221738\n",
    "Avg R squared:  0.422\n",
    "Best MAE:  0.5448859503870009\n",
    "Best R squared:  0.434\n",
    " \n",
    "                            OLS Regression Results                            \n",
    "==============================================================================\n",
    "Dep. Variable:                  yield   R-squared:                       0.702\n",
    "Model:                            OLS   Adj. R-squared:                  0.403\n",
    "Method:                 Least Squares   F-statistic:                     2.353\n",
    "Date:                Mon, 31 Mar 2025   Prob (F-statistic):              0.368\n",
    "Time:                        00:12:46   Log-Likelihood:                 2.0861\n",
    "No. Observations:                   3   AIC:                           -0.1722\n",
    "Df Residuals:                       1   BIC:                            -1.975\n",
    "Df Model:                           1                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
    "------------------------------------------------------------------------------\n",
    "const          1.1313      0.205      5.528      0.114      -1.469       3.732\n",
    "x1             0.2589      0.169      1.534      0.368      -1.885       2.403\n",
    "==============================================================================\n",
    "Omnibus:                          nan   Durbin-Watson:                   1.086\n",
    "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.368\n",
    "...\n",
    "\n",
    "non-local results:\n",
    "MAE:  0.6477484904678855\n",
    "R:  0.8377032636488345\n",
    "Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...\n",
    "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
    "  warn(\"omni_normtest is not valid with less than 8 observations; %i \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
