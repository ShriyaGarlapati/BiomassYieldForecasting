{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Date Sown</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Date of Cut</th>\n",
       "      <th>Julian Day</th>\n",
       "      <th>Plant Lodge</th>\n",
       "      <th>Plant Height</th>\n",
       "      <th>Yield % or Vernal</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Unnamed: 54</th>\n",
       "      <th>Unnamed: 55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seedway 9558</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HYTEST 410</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paragon BR</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4A421</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WL 319HQ</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State    City Date Sown  Brand       Variety Date of Cut  Julian Day  \\\n",
       "0    NY  Ithaca   5/10/02    NaN  Seedway 9558     6/15/05         NaN   \n",
       "1    NY  Ithaca   5/10/02    NaN    HYTEST 410     6/15/05         NaN   \n",
       "2    NY  Ithaca   5/10/02    NaN    Paragon BR     6/15/05         NaN   \n",
       "3    NY  Ithaca   5/10/02    NaN         4A421     6/15/05         NaN   \n",
       "4    NY  Ithaca   5/10/02    NaN      WL 319HQ     6/15/05         NaN   \n",
       "\n",
       "   Plant Lodge  Plant Height  Yield % or Vernal  ...  Unnamed: 46  \\\n",
       "0          NaN           NaN                NaN  ...          NaN   \n",
       "1          NaN           NaN                NaN  ...          NaN   \n",
       "2          NaN           NaN                NaN  ...          NaN   \n",
       "3          NaN           NaN                NaN  ...          NaN   \n",
       "4          NaN           NaN                NaN  ...          NaN   \n",
       "\n",
       "   Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50  Unnamed: 51  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55  \n",
       "0          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# read in time point 1 for training\n",
    "# train on it - model 1\n",
    "# test on tp 2\n",
    "# read tp 2\n",
    "# add it to xgb - model 2\n",
    "# test on tp 3\n",
    "# read tp 3\n",
    "# add it to xgb - model 3\n",
    "# test on tp 4\n",
    "# test model 1\n",
    "data = pd.read_csv('NY_trials_2002-2022_conv_agg_updated.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class(df):\n",
    "    # Create a DataFrame\n",
    "    print(\"Length of Dataset before class column: \", len(df))\n",
    "    # Calculate the mean and standard deviation for the Yield column\n",
    "    mean_yield = df['Yield (tons/acre)'].mean()\n",
    "    std_yield = df['Yield (tons/acre)'].std()\n",
    "\n",
    "    # Define the thresholds based on standard deviations\n",
    "    lower_threshold = mean_yield - std_yield  # Yield less than -1 stdv below mean\n",
    "    upper_threshold = mean_yield + std_yield  # Yield more than +1 stdv above mean\n",
    "\n",
    "    # Classify yields based on the thresholds\n",
    "    def classify_yield(yield_value):\n",
    "        if yield_value < lower_threshold:\n",
    "            return 0  # Low Yield (Class 1)\n",
    "        elif lower_threshold <= yield_value <= upper_threshold:\n",
    "            return 1  # Medium Yield (Class 2)\n",
    "        else:\n",
    "            return 2  # High Yield (Class 3)\n",
    "\n",
    "    # Apply the classification function to the Yield column\n",
    "    df['class'] = df['Yield (tons/acre)'].apply(classify_yield)\n",
    "\n",
    "    # Display the result\n",
    "    #print(df)\n",
    "    print(\"Length of Dataset after: \", len(df))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \n",
    "    columns_to_keep=['Yield_Diff', 'Total Solar Radiation (W/m^2)', 'Total precipitation (mm)',\n",
    "       'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'class', 'Date of Cut']\n",
    "\n",
    "    df=df[columns_to_keep]\n",
    "    #print(df.head())\n",
    "    # Rename the column\n",
    "    df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
    "    df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
    "    #df = df.rename(columns={'Yield_Diff':'yield'})\n",
    "    #data = data.rename(columns={'Total Radiation (W/m^2)':'radiation'})\n",
    "    #data = data.rename(columns={'Total Rainfall (mm)':'rain'})\n",
    "    df = df.rename(columns={'Yield_Diff': 'yield'})\n",
    "    df = df.rename(columns={'Avg Min Temp (C)':'avg_min_temp'})\n",
    "    df = df.rename(columns={'Avg Max Temp (C)':'avg_max_temp'})\n",
    "    df = df.rename(columns={'Date of Cut':'Year'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    columns_to_keep=['Yield (tons/acre)', 'Total Solar Radiation (W/m^2)', 'Total precipitation (mm)',\n",
    "       'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'Date of Cut']\n",
    "\n",
    "    df=df[columns_to_keep]\n",
    "    #print(df.head())\n",
    "    # Rename the column\n",
    "    df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
    "    df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
    "    #df3 = df3.rename(columns={'Yield_Diff':'yield'})\n",
    "    #data = data.rename(columns={'Total Radiation (W/m^2)':'radiation'})\n",
    "    #data = data.rename(columns={'Total Rainfall (mm)':'rain'})\n",
    "    df = df.rename(columns={'Avg Min Temp (C)':'avg_min_temp'})\n",
    "    df = df.rename(columns={'Avg Max Temp (C)':'avg_max_temp'})\n",
    "    df = df.rename(columns={'Date of Cut':'Year'})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_for_City(city,df):\n",
    "    city_datasets = {city: city_df for city, city_df in df.groupby(\"City\")}\n",
    "    data=city_datasets.get(city)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Year' and take the mean for numeric columns\n",
    "def create_consise_dataset(df):\n",
    "    df_grouped = df.groupby(\"Year\", as_index=False).mean(numeric_only=True)\n",
    "\n",
    "    # Add back the 'City' column (if it's the same for all rows in a group)\n",
    "    df_grouped[\"City\"] = df.groupby(\"Year\")[\"City\"].first().values\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_to_year(df):\n",
    "    df['Year'] = pd.to_datetime(df['Year'], errors='coerce')\n",
    "    # Now extract the year\n",
    "    df['Year'] = df['Year'].dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "def apply_smote(df, target_column):\n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "\n",
    "    # Count occurrences of each class\n",
    "    class_counts = y.value_counts()\n",
    "\n",
    "    # Filter out classes with only 1 sample (since SMOTE cannot handle them)\n",
    "    valid_classes = class_counts[class_counts > 1].index\n",
    "    df_filtered = df[df[target_column].isin(valid_classes)]\n",
    "\n",
    "    # Update X, y after filtering\n",
    "    X_filtered = df_filtered.drop(columns=[target_column])\n",
    "    y_filtered = df_filtered[target_column]\n",
    "\n",
    "    # Set dynamic k_neighbors (ensure it's valid)\n",
    "    min_class_size = class_counts.min()\n",
    "    k_neighbors = max(1, min(min_class_size - 1, 5))  # Ensures valid k_neighbors\n",
    "\n",
    "    # Apply SMOTE only if at least 2 classes remain\n",
    "    if len(y_filtered.unique()) > 1:\n",
    "        smote = SMOTE(sampling_strategy=\"auto\", random_state=42, k_neighbors=k_neighbors)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_filtered, y_filtered)\n",
    "\n",
    "        # Convert back to DataFrame\n",
    "        df_resampled = pd.DataFrame(X_resampled, columns=X_filtered.columns)\n",
    "        df_resampled[target_column] = y_resampled\n",
    "    else:\n",
    "        print(\"SMOTE not applied: Not enough class diversity after filtering.\")\n",
    "        return df_filtered\n",
    "\n",
    "    return df_resampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def balance_data_by_year_upsample(df):\n",
    "    \"\"\"Ensures equal number of data points for each year by upsampling to the maximum year count.\"\"\"\n",
    "    \n",
    "    # Check if 'Year' exists\n",
    "    if \"Year\" not in df.columns:\n",
    "        raise KeyError(\"The dataset does not contain a 'Year' column.\")\n",
    "    \n",
    "    # Group by 'Year' and get the count of records per year\n",
    "    year_counts = df['Year'].value_counts()\n",
    "    #print(year_counts)\n",
    "    # Get the maximum number of records across all years\n",
    "    max_count = year_counts.max()\n",
    "    #print(max_count)\n",
    "    # Initialize an empty list to store balanced data\n",
    "    balanced_data = []\n",
    "\n",
    "    # Iterate over each year and sample the same number of records\n",
    "    for year in year_counts.index:\n",
    "        year_data = df[df['Year'] == year]\n",
    "        \n",
    "        # If there are fewer data points than the maximum, upsample to the max_count\n",
    "        if len(year_data) < max_count:\n",
    "            year_data = year_data.sample(n=max_count, replace=True, random_state=42)\n",
    "            #print(\"Upsampling\")\n",
    "        # Append the sampled data to the list\n",
    "        balanced_data.append(year_data)\n",
    "    #print(balanced_data)\n",
    "    # Concatenate all the sampled data into a single DataFrame\n",
    "    balanced_df = pd.concat(balanced_data, axis=0)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE\n",
      "    Year  Yield (tons/acre)  radiation     rain  avg_min_temp  avg_max_temp\n",
      "3   2005           1.171667  348407.31  3980.27        1.5414       13.0870\n",
      "28  2005           1.390000  373548.92  4196.37        2.2246       13.8196\n",
      "9   2005           1.309167  361326.06  4070.12        1.8320       13.4049\n",
      "45  2005           0.736667  389742.63  4309.98        2.6606       14.3005\n",
      "27  2006           1.854800   30625.83   491.76       11.5036       22.9716\n",
      "Year\n",
      "2005    4\n",
      "2007    4\n",
      "2008    4\n",
      "2010    4\n",
      "2018    4\n",
      "2009    3\n",
      "2011    3\n",
      "2014    3\n",
      "2015    3\n",
      "2017    3\n",
      "2019    3\n",
      "2020    3\n",
      "2021    3\n",
      "2006    2\n",
      "2016    1\n",
      "Name: count, dtype: int64\n",
      "After SMOTE\n",
      "Year\n",
      "2005    4\n",
      "2006    4\n",
      "2007    4\n",
      "2008    4\n",
      "2009    4\n",
      "2010    4\n",
      "2011    4\n",
      "2014    4\n",
      "2015    4\n",
      "2017    4\n",
      "2018    4\n",
      "2019    4\n",
      "2020    4\n",
      "2021    4\n",
      "Name: count, dtype: int64\n",
      "Length of Dataset before class column:  56\n",
      "Length of Dataset after:  56\n",
      "56\n",
      "   Yield (tons/acre)      radiation         rain  avg_min_temp  avg_max_temp  \\\n",
      "0           1.171667  348407.310000  3980.270000      1.541400     13.087000   \n",
      "1           1.390000  373548.920000  4196.370000      2.224600     13.819600   \n",
      "2           1.309167  361326.060000  4070.120000      1.832000     13.404900   \n",
      "3           0.736667  389742.630000  4309.980000      2.660600     14.300500   \n",
      "4           1.636643   36288.621126   559.345768     11.542541     23.031124   \n",
      "\n",
      "   Year  class  \n",
      "0  2005      0  \n",
      "1  2005      0  \n",
      "2  2005      0  \n",
      "3  2005      0  \n",
      "4  2006      1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_29149/1748844638.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_29149/1748844638.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_29149/3914005513.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Year'] = pd.to_datetime(df['Year'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "data=data_cleaning(data)\n",
    "#print(data.head())\n",
    "data=split_dataset_for_City('Cobleskill',data)\n",
    "data=create_consise_dataset(data)\n",
    "# Sort by 'Year' to maintain the chronological order\n",
    "data=convert_date_to_year(data)\n",
    "data = data.sort_values(by=\"Year\")\n",
    "#print(\"Before upsampling\")\n",
    "#print(\"Before undersampling\")\n",
    "print(\"Before SMOTE\")\n",
    "data.drop(columns=['City'], inplace=True)\n",
    "print(data.head())\n",
    "\n",
    "print(data[\"Year\"].value_counts())  # Check class balance after SMOTE\n",
    "\n",
    "#data=balance_data_by_year_upsample(data)\n",
    "#data=undersampling(data)\n",
    "#print(\"After Undersampling\")\n",
    "data=apply_smote(data,'Year')\n",
    "\n",
    "\n",
    "\n",
    "print(\"After SMOTE\")\n",
    "print(data[\"Year\"].value_counts())  # Check class balance after SMOTE\n",
    "data=create_class(data)\n",
    "data = data.sort_values(by=\"Year\")\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(len(data))\n",
    "print(data.head())\n",
    "#print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2005 2006 2007 2008 2009 2010 2011 2014 2015 2017 2018 2019 2020 2021]\n"
     ]
    }
   ],
   "source": [
    "print(data['Year'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.171667  348407.310000  3980.270000      1.541400     13.087000      0\n",
      "1  1.390000  373548.920000  4196.370000      2.224600     13.819600      0\n",
      "2  1.309167  361326.060000  4070.120000      1.832000     13.404900      0\n",
      "3  0.736667  389742.630000  4309.980000      2.660600     14.300500      0\n",
      "4  1.636643   36288.621126   559.345768     11.542541     23.031124      1\n"
     ]
    }
   ],
   "source": [
    "data_Df=data[data['Year'] != 2021]\n",
    "data_Df = data_Df.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "data_Df=data_Df.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(data_Df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "52  1.778000  387164.580000  3839.540000      3.349100     14.571000      1\n",
      "53  2.491000  355017.680000  3437.960000      2.503000     13.708100      2\n",
      "54  1.482000  367072.990000  3602.460000      2.825400     14.053800      1\n",
      "55  2.285712  357470.417365  3471.428679      2.568595     13.778435      1\n"
     ]
    }
   ],
   "source": [
    "target_Df=data[data['Year'] == 2021]\n",
    "target_Df = target_Df.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "target_Df=target_Df.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(target_Df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(target_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.171667  348407.310000  3980.270000      1.541400     13.087000      0\n",
      "1  1.390000  373548.920000  4196.370000      2.224600     13.819600      0\n",
      "2  1.309167  361326.060000  4070.120000      1.832000     13.404900      0\n",
      "3  0.736667  389742.630000  4309.980000      2.660600     14.300500      0\n",
      "4  1.636643   36288.621126   559.345768     11.542541     23.031124      1\n"
     ]
    }
   ],
   "source": [
    "all_yearsDf=data\n",
    "all_yearsDf = all_yearsDf.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "all_yearsDf=all_yearsDf.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(all_yearsDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "print(len(all_yearsDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df=target_Df.dropna()\n",
    "all_yearsDf=all_yearsDf.dropna()\n",
    "data_Df=data_Df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df.reset_index(drop=True, inplace=True)\n",
    "all_yearsDf.reset_index(drop=True, inplace=True)\n",
    "data_Df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.778000  387164.580000  3839.540000      3.349100     14.571000      1\n",
      "1  2.491000  355017.680000  3437.960000      2.503000     13.708100      2\n",
      "2  1.482000  367072.990000  3602.460000      2.825400     14.053800      1\n",
      "3  2.285712  357470.417365  3471.428679      2.568595     13.778435      1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(target_Df.head())\n",
    "print(len(target_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield      radiation         rain  avg_min_temp  avg_max_temp  class\n",
      "0  1.171667  348407.310000  3980.270000      1.541400     13.087000      0\n",
      "1  1.390000  373548.920000  4196.370000      2.224600     13.819600      0\n",
      "2  1.309167  361326.060000  4070.120000      1.832000     13.404900      0\n",
      "3  0.736667  389742.630000  4309.980000      2.660600     14.300500      0\n",
      "4  1.636643   36288.621126   559.345768     11.542541     23.031124      1\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print(all_yearsDf.head())\n",
    "print(len(all_yearsDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Df.to_csv(\"data_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "print(len(data_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records to generate:  3846\n",
      "Number of records to generate:  11154\n",
      "Number of records to generate:  5000\n"
     ]
    }
   ],
   "source": [
    "# from sdv.tabular import TVAE\n",
    "\n",
    "# model = TVAE()\n",
    "# model.fit(data)\n",
    "import numpy as np\n",
    "samples_out = 20000 # total number of samples/records to generate/synthesize\n",
    "no_stds = 1 # number of standard deviations within which synthesized values must fall\n",
    "number_of_classes = (data1['class'].unique()).size # number of unique classes in input data\n",
    "\n",
    "data_len = len(data1.index)\n",
    "F = [] # a list of the feature vectors dataframes, one per class\n",
    "for class_no in range(number_of_classes):\n",
    "    df = pd.DataFrame(data1[data1['class'] == class_no])\n",
    "    #print(\"In F: \")\n",
    "    #print(check_nan_in_dataframe(df))\n",
    "    F.append(df)\n",
    "\n",
    "\n",
    "def synthesize_tabular_data(F, samples_out, no_stds, no_classes, no_records):\n",
    "    new_F = []\n",
    "    for index, entry in enumerate(F):\n",
    "        # Clean NaN values before processing\n",
    "        entry = entry.dropna(subset=['yield', 'radiation', 'rain', 'avg_max_temp', 'avg_min_temp'])\n",
    "\n",
    "        # Check if there's data left after dropping NaN values\n",
    "        if len(entry) == 0:\n",
    "            print(f\"Warning: Class {index} has no valid data after removing NaNs.\")\n",
    "            continue\n",
    "        yield_ = entry['yield']\n",
    "        mean_yield = yield_.mean()\n",
    "        std_yield = yield_.std()\n",
    "        total_rad = entry['radiation']\n",
    "        mean_rad = total_rad.mean()\n",
    "        std_rad = total_rad.std()\n",
    "        total_rain = entry['rain']\n",
    "        mean_rain = total_rain.mean()\n",
    "        std_rain = total_rain.std()\n",
    "        avg_max_temp = entry['avg_max_temp']\n",
    "        mean_max_temp = avg_max_temp.mean()\n",
    "        std_max_temp = avg_max_temp.std()\n",
    "        avg_min_temp = entry['avg_min_temp']\n",
    "        mean_min_temp = avg_min_temp.mean()\n",
    "        std_min_temp = avg_min_temp.std()\n",
    "        \n",
    "        #print(str(mean_yield) + \" \" + str(std_yield) + \" \" + str(mean_rad) + \" \" + str(std_rad) + \" \" + str(mean_rain) + \" \" + str(std_rain) + \" \" + str(mean_max_temp) + \" \" + str(std_max_temp) + \" \" + str(mean_min_temp) + \" \" + str(std_min_temp))\n",
    "        # Check for NaNs in calculated values\n",
    "        if np.isnan(mean_yield) or np.isnan(std_yield):\n",
    "            print(f\"Warning: NaN found in 'yield' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_rad) or np.isnan(std_rad):\n",
    "            print(f\"Warning: NaN found in 'radiation' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_rain) or np.isnan(std_rain):\n",
    "            print(f\"Warning: NaN found in 'rain' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_max_temp) or np.isnan(std_max_temp):\n",
    "            print(f\"Warning: NaN found in 'avg_max_temp' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_min_temp) or np.isnan(std_min_temp):\n",
    "            print(f\"Warning: NaN found in 'avg_min_temp' statistics for class {index}.\")\n",
    "            continue\n",
    "        \n",
    "        new_yields = []\n",
    "        new_rads = []\n",
    "        new_rains = []\n",
    "        new_max_temps = []\n",
    "        new_min_temps = []\n",
    "        \n",
    "        # calculate potcii: percentage of this class in input\n",
    "        potcii = (len(entry)/no_records)\n",
    "        no_records_to_generate = round(potcii * samples_out)\n",
    "        print(\"Number of records to generate: \", no_records_to_generate)\n",
    "        for i in range(no_records_to_generate):\n",
    "            new_yield = random.uniform(mean_yield - std_yield*no_stds, mean_yield + std_yield*no_stds)\n",
    "            new_yields.append(new_yield)\n",
    "            #print(\"New Yields:\")\n",
    "            #print(new_yields)\n",
    "            \n",
    "            new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "            new_rads.append(new_rad)\n",
    "            #print(\"Radiation:\")\n",
    "            #print(new_rads)\n",
    "            \n",
    "            new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "            new_rains.append(new_rain)\n",
    "            #print(\"Precipitation:\")\n",
    "            #print(new_rains)\n",
    "        \n",
    "            new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "            new_max_temps.append(new_max_temp)\n",
    "            #print(\"Max Temp:\")\n",
    "            #print(new_max_temps)\n",
    "            \n",
    "            new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "            new_min_temps.append(new_min_temp)\n",
    "            #print(\"Min Temperature\")\n",
    "            #print(new_min_temps)\n",
    "            \n",
    "        # Create a DataFrame for the new synthesized data\n",
    "        new_data = pd.DataFrame({\n",
    "            'yield': new_yields,\n",
    "            'radiation': new_rads,\n",
    "            'rain': new_rains,\n",
    "            'avg_max_temp': new_max_temps,\n",
    "            'avg_min_temp': new_min_temps,\n",
    "            'class': [index] * len(new_yields)  # Adding the class label\n",
    "        })\n",
    "        \n",
    "        # Concatenate the original data with the new synthesized data\n",
    "        concat_data = pd.concat([entry, new_data], ignore_index=True)\n",
    "        \n",
    "        # Append the concatenated DataFrame to the list\n",
    "        new_F.append(concat_data)\n",
    "    \n",
    "    # Finally, concatenate all class DataFrames into a single DataFrame\n",
    "    final_data = pd.concat(new_F, ignore_index=True)\n",
    "    \n",
    "    return final_data\n",
    "    #return pd.concat(new_F)\n",
    "\n",
    "new_data = synthesize_tabular_data(F, samples_out, no_stds, number_of_classes, data_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20052\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(\"data_no_2022_synthesized_nonstationary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df.reset_index(drop=True, inplace=True)\n",
    "all_yearsDf.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yearsDf.to_csv(\"all_years.csv\", index=False)\n",
    "target_Df.to_csv(\"target_yearDf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
