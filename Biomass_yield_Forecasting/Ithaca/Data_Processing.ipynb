{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Date Sown</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Date of Cut</th>\n",
       "      <th>Julian Day</th>\n",
       "      <th>Plant Lodge</th>\n",
       "      <th>Plant Height</th>\n",
       "      <th>Yield % or Vernal</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "      <th>Unnamed: 50</th>\n",
       "      <th>Unnamed: 51</th>\n",
       "      <th>Unnamed: 52</th>\n",
       "      <th>Unnamed: 53</th>\n",
       "      <th>Unnamed: 54</th>\n",
       "      <th>Unnamed: 55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seedway 9558</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HYTEST 410</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paragon BR</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4A421</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NY</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>5/10/02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WL 319HQ</td>\n",
       "      <td>6/15/05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State    City Date Sown  Brand       Variety Date of Cut  Julian Day  \\\n",
       "0    NY  Ithaca   5/10/02    NaN  Seedway 9558     6/15/05         NaN   \n",
       "1    NY  Ithaca   5/10/02    NaN    HYTEST 410     6/15/05         NaN   \n",
       "2    NY  Ithaca   5/10/02    NaN    Paragon BR     6/15/05         NaN   \n",
       "3    NY  Ithaca   5/10/02    NaN         4A421     6/15/05         NaN   \n",
       "4    NY  Ithaca   5/10/02    NaN      WL 319HQ     6/15/05         NaN   \n",
       "\n",
       "   Plant Lodge  Plant Height  Yield % or Vernal  ...  Unnamed: 46  \\\n",
       "0          NaN           NaN                NaN  ...          NaN   \n",
       "1          NaN           NaN                NaN  ...          NaN   \n",
       "2          NaN           NaN                NaN  ...          NaN   \n",
       "3          NaN           NaN                NaN  ...          NaN   \n",
       "4          NaN           NaN                NaN  ...          NaN   \n",
       "\n",
       "   Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50  Unnamed: 51  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55  \n",
       "0          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "# read in time point 1 for training\n",
    "# train on it - model 1\n",
    "# test on tp 2\n",
    "# read tp 2\n",
    "# add it to xgb - model 2\n",
    "# test on tp 3\n",
    "# read tp 3\n",
    "# add it to xgb - model 3\n",
    "# test on tp 4\n",
    "# test model 1\n",
    "data = pd.read_csv('NY_trials_2002-2022_conv_agg_updated.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class(df):\n",
    "    # Create a DataFrame\n",
    "    print(\"Length of Dataset before class column: \", len(df))\n",
    "    # Calculate the mean and standard deviation for the Yield column\n",
    "    mean_yield = df['Yield (tons/acre)'].mean()\n",
    "    std_yield = df['Yield (tons/acre)'].std()\n",
    "\n",
    "    # Define the thresholds based on standard deviations\n",
    "    lower_threshold = mean_yield - std_yield  # Yield less than -1 stdv below mean\n",
    "    upper_threshold = mean_yield + std_yield  # Yield more than +1 stdv above mean\n",
    "\n",
    "    # Classify yields based on the thresholds\n",
    "    def classify_yield(yield_value):\n",
    "        if yield_value < lower_threshold:\n",
    "            return 0  # Low Yield (Class 1)\n",
    "        elif lower_threshold <= yield_value <= upper_threshold:\n",
    "            return 1  # Medium Yield (Class 2)\n",
    "        else:\n",
    "            return 2  # High Yield (Class 3)\n",
    "\n",
    "    # Apply the classification function to the Yield column\n",
    "    df['class'] = df['Yield (tons/acre)'].apply(classify_yield)\n",
    "\n",
    "    # Display the result\n",
    "    #print(df)\n",
    "    print(\"Length of Dataset after: \", len(df))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    \n",
    "    columns_to_keep=['Yield_Diff', 'Total Solar Radiation (W/m^2)', 'Total precipitation (mm)',\n",
    "       'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'class', 'Date of Cut']\n",
    "\n",
    "    df=df[columns_to_keep]\n",
    "    #print(df.head())\n",
    "    # Rename the column\n",
    "    df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
    "    df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
    "    #df = df.rename(columns={'Yield_Diff':'yield'})\n",
    "    #data = data.rename(columns={'Total Radiation (W/m^2)':'radiation'})\n",
    "    #data = data.rename(columns={'Total Rainfall (mm)':'rain'})\n",
    "    df = df.rename(columns={'Yield_Diff': 'yield'})\n",
    "    df = df.rename(columns={'Avg Min Temp (C)':'avg_min_temp'})\n",
    "    df = df.rename(columns={'Avg Max Temp (C)':'avg_max_temp'})\n",
    "    df = df.rename(columns={'Date of Cut':'Year'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    columns_to_keep=['Yield (tons/acre)', 'Total Solar Radiation (W/m^2)', 'Total precipitation (mm)',\n",
    "       'Avg Min Temp (C)', 'Avg Max Temp (C)', 'City', 'Date of Cut']\n",
    "\n",
    "    df=df[columns_to_keep]\n",
    "    #print(df.head())\n",
    "    # Rename the column\n",
    "    df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
    "    df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
    "    #df3 = df3.rename(columns={'Yield_Diff':'yield'})\n",
    "    #data = data.rename(columns={'Total Radiation (W/m^2)':'radiation'})\n",
    "    #data = data.rename(columns={'Total Rainfall (mm)':'rain'})\n",
    "    df = df.rename(columns={'Avg Min Temp (C)':'avg_min_temp'})\n",
    "    df = df.rename(columns={'Avg Max Temp (C)':'avg_max_temp'})\n",
    "    df = df.rename(columns={'Date of Cut':'Year'})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_for_City(city,df):\n",
    "    city_datasets = {city: city_df for city, city_df in df.groupby(\"City\")}\n",
    "    data=city_datasets.get(city)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Year' and take the mean for numeric columns\n",
    "def create_consise_dataset(df):\n",
    "    df_grouped = df.groupby(\"Year\", as_index=False).mean(numeric_only=True)\n",
    "\n",
    "    # Add back the 'City' column (if it's the same for all rows in a group)\n",
    "    df_grouped[\"City\"] = df.groupby(\"Year\")[\"City\"].first().values\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date_to_year(df):\n",
    "    df['Year'] = pd.to_datetime(df['Year'], errors='coerce')\n",
    "    # Now extract the year\n",
    "    df['Year'] = df['Year'].dt.year\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from imbalanced-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "def apply_smote(df, target_column):\n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    # Get class distribution\n",
    "    class_counts = y.value_counts()\n",
    "    # Ensure each class gets at least as many samples as it originally had\n",
    "    sampling_strategy = {cls: max(int(max(class_counts) * 1.0), count) for cls, count in class_counts.items()}\n",
    "\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy, random_state=42, k_neighbors=2)\n",
    "    # Initialize SMOTE\n",
    "    #smote = SMOTE(sampling_strategy=0.5, random_state=42, k_neighbors=2)\n",
    "\n",
    "    # Apply SMOTE to generate synthetic samples\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    # Convert back to DataFrame\n",
    "    df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    df_resampled[target_column] = y_resampled\n",
    "\n",
    "    return df_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def balance_data_by_year_upsample(df):\n",
    "    \"\"\"Ensures equal number of data points for each year by upsampling to the maximum year count.\"\"\"\n",
    "    \n",
    "    # Check if 'Year' exists\n",
    "    if \"Year\" not in df.columns:\n",
    "        raise KeyError(\"The dataset does not contain a 'Year' column.\")\n",
    "    \n",
    "    # Group by 'Year' and get the count of records per year\n",
    "    year_counts = df['Year'].value_counts()\n",
    "    #print(year_counts)\n",
    "    # Get the maximum number of records across all years\n",
    "    max_count = year_counts.max()\n",
    "    #print(max_count)\n",
    "    # Initialize an empty list to store balanced data\n",
    "    balanced_data = []\n",
    "\n",
    "    # Iterate over each year and sample the same number of records\n",
    "    for year in year_counts.index:\n",
    "        year_data = df[df['Year'] == year]\n",
    "        \n",
    "        # If there are fewer data points than the maximum, upsample to the max_count\n",
    "        if len(year_data) < max_count:\n",
    "            year_data = year_data.sample(n=max_count, replace=True, random_state=42)\n",
    "            #print(\"Upsampling\")\n",
    "        # Append the sampled data to the list\n",
    "        balanced_data.append(year_data)\n",
    "    #print(balanced_data)\n",
    "    # Concatenate all the sampled data into a single DataFrame\n",
    "    balanced_df = pd.concat(balanced_data, axis=0)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset before preprocessing:  7344\n",
      "No preprocessing------\n",
      "  State    City Date Sown  Brand       Variety Date of Cut  Julian Day  \\\n",
      "0    NY  Ithaca   5/10/02    NaN  Seedway 9558     6/15/05         NaN   \n",
      "1    NY  Ithaca   5/10/02    NaN    HYTEST 410     6/15/05         NaN   \n",
      "2    NY  Ithaca   5/10/02    NaN    Paragon BR     6/15/05         NaN   \n",
      "3    NY  Ithaca   5/10/02    NaN         4A421     6/15/05         NaN   \n",
      "4    NY  Ithaca   5/10/02    NaN      WL 319HQ     6/15/05         NaN   \n",
      "\n",
      "   Plant Lodge  Plant Height  Yield % or Vernal  ...  Unnamed: 46  \\\n",
      "0          NaN           NaN                NaN  ...          NaN   \n",
      "1          NaN           NaN                NaN  ...          NaN   \n",
      "2          NaN           NaN                NaN  ...          NaN   \n",
      "3          NaN           NaN                NaN  ...          NaN   \n",
      "4          NaN           NaN                NaN  ...          NaN   \n",
      "\n",
      "   Unnamed: 47  Unnamed: 48  Unnamed: 49  Unnamed: 50  Unnamed: 51  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 52  Unnamed: 53  Unnamed: 54  Unnamed: 55  \n",
      "0          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 56 columns]\n",
      "Dataset after preprocessing:  7344\n",
      "Data after preprocessing--------\n",
      "   Yield (tons/acre)  radiation     rain  avg_min_temp  avg_max_temp    City  \\\n",
      "0               2.13  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "1               2.19  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "2               2.11  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "3               2.17  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "4               2.15  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "\n",
      "      Year  \n",
      "0  6/15/05  \n",
      "1  6/15/05  \n",
      "2  6/15/05  \n",
      "3  6/15/05  \n",
      "4  6/15/05  \n",
      "   Yield (tons/acre)  radiation     rain  avg_min_temp  avg_max_temp    City  \\\n",
      "0               2.13  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "1               2.19  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "2               2.11  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "3               2.17  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "4               2.15  341395.76  3618.14        2.3466       13.2826  Ithaca   \n",
      "\n",
      "      Year  \n",
      "0  6/15/05  \n",
      "1  6/15/05  \n",
      "2  6/15/05  \n",
      "3  6/15/05  \n",
      "4  6/15/05  \n",
      "Dataset after splitting Ithaca  4320\n",
      "After creating concise dataset  223\n",
      "      Year  Yield (tons/acre)      radiation         rain  avg_min_temp  \\\n",
      "0  10/6/22           0.828125  166501.710000  1770.610000      5.730000   \n",
      "1  10/7/21           0.563333  382732.090000  4054.130000      4.277400   \n",
      "2   6/1/09           2.140000  287859.680000  2634.025000      2.528150   \n",
      "3   6/1/22           1.475000  195278.820000  2047.520000      2.354800   \n",
      "4  6/10/10           2.945556  221830.716667  1921.694815      2.932715   \n",
      "\n",
      "   avg_max_temp    City  \n",
      "0     17.219800  Ithaca  \n",
      "1     15.080400  Ithaca  \n",
      "2     13.812250  Ithaca  \n",
      "3     13.240400  Ithaca  \n",
      "4     14.045259  Ithaca  \n",
      "<class 'pandas.core.series.Series'>\n",
      "Before SMOTE\n",
      "Before SMOTE  223\n",
      "     Year  Yield (tons/acre)      radiation         rain  avg_min_temp  \\\n",
      "52   2005           1.421923  230454.950000  2535.380000      2.449000   \n",
      "56   2005           2.038261  118368.720000  1340.700000      2.653400   \n",
      "19   2005           2.089545  341395.760000  3618.140000      2.346600   \n",
      "80   2005           1.868367  192228.728163  2104.189592      3.384498   \n",
      "116  2005           1.770909  358003.820000  3721.110000      2.805700   \n",
      "\n",
      "     avg_max_temp  \n",
      "52      13.306700  \n",
      "56      13.607200  \n",
      "19      13.282600  \n",
      "80      14.368527  \n",
      "116     13.793200  \n",
      "Year\n",
      "2008    17\n",
      "2016    17\n",
      "2019    17\n",
      "2020    17\n",
      "2007    16\n",
      "2011    16\n",
      "2015    16\n",
      "2021    16\n",
      "2010    15\n",
      "2006    14\n",
      "2017    14\n",
      "2009    13\n",
      "2018    13\n",
      "2022    10\n",
      "2005     9\n",
      "2014     3\n",
      "Name: count, dtype: int64\n",
      "After considering only 4 dates of cut per year:\n",
      "Year\n",
      "2005    6\n",
      "2006    6\n",
      "2007    6\n",
      "2008    6\n",
      "2009    6\n",
      "2010    6\n",
      "2011    6\n",
      "2014    3\n",
      "2015    6\n",
      "2016    6\n",
      "2017    6\n",
      "2018    6\n",
      "2019    6\n",
      "2020    6\n",
      "2021    6\n",
      "2022    6\n",
      "Name: count, dtype: int64\n",
      "After SMOTE\n",
      "After SMOTE  96\n",
      "Year\n",
      "2005    6\n",
      "2006    6\n",
      "2007    6\n",
      "2008    6\n",
      "2009    6\n",
      "2010    6\n",
      "2011    6\n",
      "2014    6\n",
      "2015    6\n",
      "2016    6\n",
      "2017    6\n",
      "2018    6\n",
      "2019    6\n",
      "2020    6\n",
      "2021    6\n",
      "2022    6\n",
      "Name: count, dtype: int64\n",
      "Length of Dataset before class column:  96\n",
      "Length of Dataset after:  96\n",
      "96\n",
      "   Yield (tons/acre)  radiation     rain  avg_min_temp  avg_max_temp  Year  \\\n",
      "0           0.766452   48010.95   301.99       12.4369       25.5838  2005   \n",
      "1           2.038261  118368.72  1340.70        2.6534       13.6072  2005   \n",
      "2           1.129565  148923.23  1512.65        4.7696       16.0500  2005   \n",
      "3           1.421923  230454.95  2535.38        2.4490       13.3067  2005   \n",
      "4           0.768636  373381.00  3837.77        3.1904       14.2618  2005   \n",
      "\n",
      "   class  \n",
      "0      0  \n",
      "1      1  \n",
      "2      1  \n",
      "3      1  \n",
      "4      0  \n",
      "Finally:  96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_1554/1748844638.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Total Solar Radiation (W/m^2)': 'radiation'}, inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_1554/1748844638.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Total precipitation (mm)': 'rain'}, inplace=True)\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_1554/276365731.py:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data['Year'] = pd.to_datetime(data['Year'])\n",
      "/var/folders/zn/_j79f2r529s6w4hp6tkpln8c0000gn/T/ipykernel_1554/276365731.py:38: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_limited = data.groupby('Year').apply(lambda x: x.sample(n=6, random_state=42) if len(x) >= 4 else x)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset before preprocessing: \", len(data))\n",
    "print(\"No preprocessing------\")\n",
    "print(data.head())\n",
    "data=data_cleaning(data)\n",
    "print(\"Dataset after preprocessing: \", len(data))\n",
    "print(\"Data after preprocessing--------\")\n",
    "print(data.head())\n",
    "#print(data.head())\n",
    "data=split_dataset_for_City('Ithaca',data)\n",
    "data.to_csv(\"Ithaca_NY_not_preprocessed.csv\", index=False)\n",
    "print(data.head())\n",
    "print(\"Dataset after splitting Ithaca \", len(data))\n",
    "data=create_consise_dataset(data)\n",
    "print(\"After creating concise dataset \", len(data))\n",
    "# Sort by 'Year' to maintain the chronological order\n",
    "print(data.head())\n",
    "print(type(data['Year']))\n",
    "data['Year'] = pd.to_datetime(data['Year'])\n",
    "\n",
    "# Sort by date\n",
    "data = data.sort_values(by='Year')\n",
    "\n",
    "data.to_csv(\"Ithaca_sorted_by_date.csv\", index=False)\n",
    "data=convert_date_to_year(data)\n",
    "\n",
    "\n",
    "#print(\"Before upsampling\")\n",
    "#print(\"Before undersampling\")\n",
    "print(\"Before SMOTE\")\n",
    "print(\"Before SMOTE \", len(data))\n",
    "data.to_csv(\"Ithaca_NY_preprocessed_before_SMOTE.csv\", index=False)\n",
    "data.drop(columns=['City'], inplace=True)\n",
    "print(data.head())\n",
    "\n",
    "print(data[\"Year\"].value_counts())  # Check class balance BEFORE SMOTE\n",
    "\n",
    "# Group by 'Year' and take 6 records per year\n",
    "df_limited = data.groupby('Year').apply(lambda x: x.sample(n=6, random_state=42) if len(x) >= 4 else x)\n",
    "\n",
    "# Optional: remove multi-index created by groupby\n",
    "df_limited.reset_index(drop=True, inplace=True)\n",
    "print(\"After considering only 4 dates of cut per year:\")\n",
    "\n",
    "# Check the result\n",
    "print(df_limited['Year'].value_counts().sort_index())\n",
    "#data=balance_data_by_year_upsample(data)\n",
    "#data=undersampling(data)\n",
    "#print(\"After Undersampling\")\n",
    "data=df_limited\n",
    "data=apply_smote(data,'Year')\n",
    "\n",
    "\n",
    "\n",
    "print(\"After SMOTE\")\n",
    "print(\"After SMOTE \", len(data))\n",
    "data.to_csv(\"Ithaca_NY_preprocessed_after_SMOTE.csv\", index=False)\n",
    "print(data[\"Year\"].value_counts())  # Check class balance after SMOTE\n",
    "data=create_class(data)\n",
    "data = data.sort_values(by=\"Year\")\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(len(data))\n",
    "print(data.head())\n",
    "#print(data.head())\n",
    "print(\"Finally: \",len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.766452   48010.95   301.99       12.4369       25.5838      0\n",
      "1  2.038261  118368.72  1340.70        2.6534       13.6072      1\n",
      "2  1.129565  148923.23  1512.65        4.7696       16.0500      1\n",
      "3  1.421923  230454.95  2535.38        2.4490       13.3067      1\n",
      "4  0.768636  373381.00  3837.77        3.1904       14.2618      0\n"
     ]
    }
   ],
   "source": [
    "data_Df=data[data['Year'] != 2022]\n",
    "data_Df = data_Df.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "data_Df=data_Df.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(data_Df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "90  0.929048  366120.81  3652.99        4.0495       15.1828      0\n",
      "91  1.466250  124268.43  1424.11        3.7791       14.9567      1\n",
      "92  0.738810  350854.89  3450.55        3.6339       14.7335      0\n",
      "93  1.475000  195278.82  2047.52        2.3548       13.2404      1\n",
      "94  1.076000  228828.84  2269.57        3.5858       14.7590      1\n"
     ]
    }
   ],
   "source": [
    "target_Df=data[data['Year'] == 2022]\n",
    "target_Df = target_Df.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "target_Df=target_Df.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(target_Df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(target_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.766452   48010.95   301.99       12.4369       25.5838      0\n",
      "1  2.038261  118368.72  1340.70        2.6534       13.6072      1\n",
      "2  1.129565  148923.23  1512.65        4.7696       16.0500      1\n",
      "3  1.421923  230454.95  2535.38        2.4490       13.3067      1\n",
      "4  0.768636  373381.00  3837.77        3.1904       14.2618      0\n"
     ]
    }
   ],
   "source": [
    "all_yearsDf=data\n",
    "all_yearsDf = all_yearsDf.rename(columns={'Yield (tons/acre)':'yield'})\n",
    "#print(len(target_yearDf))\n",
    "#print(target_yearDf.head())\n",
    "# Display the filtered DataFrame\n",
    "all_yearsDf=all_yearsDf.drop(columns={'Year'}, inplace=False)\n",
    "#print(final_yearDf)\n",
    "print(all_yearsDf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    }
   ],
   "source": [
    "print(len(all_yearsDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df=target_Df.dropna()\n",
    "all_yearsDf=all_yearsDf.dropna()\n",
    "data_Df=data_Df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df.reset_index(drop=True, inplace=True)\n",
    "all_yearsDf.reset_index(drop=True, inplace=True)\n",
    "data_Df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.929048  366120.81  3652.99        4.0495       15.1828      0\n",
      "1  1.466250  124268.43  1424.11        3.7791       14.9567      1\n",
      "2  0.738810  350854.89  3450.55        3.6339       14.7335      0\n",
      "3  1.475000  195278.82  2047.52        2.3548       13.2404      1\n",
      "4  1.076000  228828.84  2269.57        3.5858       14.7590      1\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(target_Df.head())\n",
    "print(len(target_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      yield  radiation     rain  avg_min_temp  avg_max_temp  class\n",
      "0  0.766452   48010.95   301.99       12.4369       25.5838      0\n",
      "1  2.038261  118368.72  1340.70        2.6534       13.6072      1\n",
      "2  1.129565  148923.23  1512.65        4.7696       16.0500      1\n",
      "3  1.421923  230454.95  2535.38        2.4490       13.3067      1\n",
      "4  0.768636  373381.00  3837.77        3.1904       14.2618      0\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "print(all_yearsDf.head())\n",
    "print(len(all_yearsDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Df.to_csv(\"data_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "print(len(data_Df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data_Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records to generate:  3333\n",
      "Number of records to generate:  12667\n",
      "Number of records to generate:  4000\n"
     ]
    }
   ],
   "source": [
    "# from sdv.tabular import TVAE\n",
    "\n",
    "# model = TVAE()\n",
    "# model.fit(data)\n",
    "import numpy as np\n",
    "samples_out = 20000 # total number of samples/records to generate/synthesize\n",
    "no_stds = 1 # number of standard deviations within which synthesized values must fall\n",
    "number_of_classes = (data1['class'].unique()).size # number of unique classes in input data\n",
    "\n",
    "data_len = len(data1.index)\n",
    "F = [] # a list of the feature vectors dataframes, one per class\n",
    "for class_no in range(number_of_classes):\n",
    "    df = pd.DataFrame(data1[data1['class'] == class_no])\n",
    "    #print(\"In F: \")\n",
    "    #print(check_nan_in_dataframe(df))\n",
    "    F.append(df)\n",
    "\n",
    "\n",
    "def synthesize_tabular_data(F, samples_out, no_stds, no_classes, no_records):\n",
    "    new_F = []\n",
    "    for index, entry in enumerate(F):\n",
    "        # Clean NaN values before processing\n",
    "        entry = entry.dropna(subset=['yield', 'radiation', 'rain', 'avg_max_temp', 'avg_min_temp'])\n",
    "\n",
    "        # Check if there's data left after dropping NaN values\n",
    "        if len(entry) == 0:\n",
    "            print(f\"Warning: Class {index} has no valid data after removing NaNs.\")\n",
    "            continue\n",
    "        yield_ = entry['yield']\n",
    "        mean_yield = yield_.mean()\n",
    "        std_yield = yield_.std()\n",
    "        total_rad = entry['radiation']\n",
    "        mean_rad = total_rad.mean()\n",
    "        std_rad = total_rad.std()\n",
    "        total_rain = entry['rain']\n",
    "        mean_rain = total_rain.mean()\n",
    "        std_rain = total_rain.std()\n",
    "        avg_max_temp = entry['avg_max_temp']\n",
    "        mean_max_temp = avg_max_temp.mean()\n",
    "        std_max_temp = avg_max_temp.std()\n",
    "        avg_min_temp = entry['avg_min_temp']\n",
    "        mean_min_temp = avg_min_temp.mean()\n",
    "        std_min_temp = avg_min_temp.std()\n",
    "        \n",
    "        #print(str(mean_yield) + \" \" + str(std_yield) + \" \" + str(mean_rad) + \" \" + str(std_rad) + \" \" + str(mean_rain) + \" \" + str(std_rain) + \" \" + str(mean_max_temp) + \" \" + str(std_max_temp) + \" \" + str(mean_min_temp) + \" \" + str(std_min_temp))\n",
    "        # Check for NaNs in calculated values\n",
    "        if np.isnan(mean_yield) or np.isnan(std_yield):\n",
    "            print(f\"Warning: NaN found in 'yield' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_rad) or np.isnan(std_rad):\n",
    "            print(f\"Warning: NaN found in 'radiation' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_rain) or np.isnan(std_rain):\n",
    "            print(f\"Warning: NaN found in 'rain' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_max_temp) or np.isnan(std_max_temp):\n",
    "            print(f\"Warning: NaN found in 'avg_max_temp' statistics for class {index}.\")\n",
    "            continue\n",
    "        if np.isnan(mean_min_temp) or np.isnan(std_min_temp):\n",
    "            print(f\"Warning: NaN found in 'avg_min_temp' statistics for class {index}.\")\n",
    "            continue\n",
    "        \n",
    "        new_yields = []\n",
    "        new_rads = []\n",
    "        new_rains = []\n",
    "        new_max_temps = []\n",
    "        new_min_temps = []\n",
    "        \n",
    "        # calculate potcii: percentage of this class in input\n",
    "        potcii = (len(entry)/no_records)\n",
    "        no_records_to_generate = round(potcii * samples_out)\n",
    "        print(\"Number of records to generate: \", no_records_to_generate)\n",
    "        for i in range(no_records_to_generate):\n",
    "            new_yield = random.uniform(mean_yield - std_yield*no_stds, mean_yield + std_yield*no_stds)\n",
    "            new_yields.append(new_yield)\n",
    "            #print(\"New Yields:\")\n",
    "            #print(new_yields)\n",
    "            \n",
    "            new_rad = random.uniform(mean_rad - std_rad*no_stds, mean_rad + std_rad*no_stds)\n",
    "            new_rads.append(new_rad)\n",
    "            #print(\"Radiation:\")\n",
    "            #print(new_rads)\n",
    "            \n",
    "            new_rain = random.uniform(mean_rain - std_rain*no_stds, mean_rain + std_rain*no_stds)\n",
    "            new_rains.append(new_rain)\n",
    "            #print(\"Precipitation:\")\n",
    "            #print(new_rains)\n",
    "        \n",
    "            new_max_temp = random.uniform(mean_max_temp - std_max_temp*no_stds, mean_max_temp + std_max_temp*no_stds)\n",
    "            new_max_temps.append(new_max_temp)\n",
    "            #print(\"Max Temp:\")\n",
    "            #print(new_max_temps)\n",
    "            \n",
    "            new_min_temp = random.uniform(mean_min_temp - std_min_temp*no_stds, mean_min_temp + std_min_temp*no_stds)\n",
    "            new_min_temps.append(new_min_temp)\n",
    "            #print(\"Min Temperature\")\n",
    "            #print(new_min_temps)\n",
    "            \n",
    "        # Create a DataFrame for the new synthesized data\n",
    "        new_data = pd.DataFrame({\n",
    "            'yield': new_yields,\n",
    "            'radiation': new_rads,\n",
    "            'rain': new_rains,\n",
    "            'avg_max_temp': new_max_temps,\n",
    "            'avg_min_temp': new_min_temps,\n",
    "            'class': [index] * len(new_yields)  # Adding the class label\n",
    "        })\n",
    "        \n",
    "        # Concatenate the original data with the new synthesized data\n",
    "        concat_data = pd.concat([entry, new_data], ignore_index=True)\n",
    "        \n",
    "        # Append the concatenated DataFrame to the list\n",
    "        new_F.append(concat_data)\n",
    "    \n",
    "    # Finally, concatenate all class DataFrames into a single DataFrame\n",
    "    final_data = pd.concat(new_F, ignore_index=True)\n",
    "    \n",
    "    return final_data\n",
    "    #return pd.concat(new_F)\n",
    "\n",
    "new_data = synthesize_tabular_data(F, samples_out, no_stds, number_of_classes, data_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20090\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(\"data_no_2022_synthesized_nonstationary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_Df.reset_index(drop=True, inplace=True)\n",
    "all_yearsDf.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_yearsDf.to_csv(\"all_years.csv\", index=False)\n",
    "target_Df.to_csv(\"target_yearDf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
